{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3f0c540",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSolved:\\n    -It's possible for train-test split to split data in such a way, that\\n   after encoding, X_train and X_test have different numbers of features.\\n   Split has to be rerun to fix it. First encode, then split again?\\n   BUT IT STILL HAS TO BE ENCODED AND SPLIT BEFORE STARTING CROSS VALIDATION\\n   AND SEQUENTIAL FEATURE SELECTION. MAYBE APPEND DURING SPLIT AND THEN SPLIT\\n   AGAIN?\\n    -Improve feature encoding to have proper ordering instead of random numbers\\n    which currently influence classification accuracy:\\n    https://datascience.stackexchange.com/questions/72343/encoding-with-ordinalencoder-how-to-give-levels-as-user-input\\n\\nFishy:\\n    -check and check for data leakage (def: https://scikit-learn.org/stable/glossary.html)\\n\\nPickup: \\n    -move over feature encoding to pd.get_dummies() if it can be adapted\\n    -put the classifier in SFS\\nTODO:\\n    -modify SFS to check each predict_proba and stop if threshold is hit\\n    -add cost counting to SFS wrapper\\n    -???\\n    -tests and profit???\\n    -report a bug with indexes when predicting X_test using audiology and \\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Solved:\n",
    "    -It's possible for train-test split to split data in such a way, that\n",
    "   after encoding, X_train and X_test have different numbers of features.\n",
    "   Split has to be rerun to fix it. First encode, then split again?\n",
    "   BUT IT STILL HAS TO BE ENCODED AND SPLIT BEFORE STARTING CROSS VALIDATION\n",
    "   AND SEQUENTIAL FEATURE SELECTION. MAYBE APPEND DURING SPLIT AND THEN SPLIT\n",
    "   AGAIN?\n",
    "    -Improve feature encoding to have proper ordering instead of random numbers\n",
    "    which currently influence classification accuracy:\n",
    "    https://datascience.stackexchange.com/questions/72343/encoding-with-ordinalencoder-how-to-give-levels-as-user-input\n",
    "\n",
    "Fishy:\n",
    "    -check and check for data leakage (def: https://scikit-learn.org/stable/glossary.html)\n",
    "\n",
    "Pickup: \n",
    "    -move over feature encoding to pd.get_dummies() if it can be adapted\n",
    "    -put the classifier in SFS\n",
    "TODO:\n",
    "    -modify SFS to check each predict_proba and stop if threshold is hit\n",
    "    -add cost counting to SFS wrapper\n",
    "    -???\n",
    "    -tests and profit???\n",
    "    -report a bug with indexes when predicting X_test using audiology and \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c628d317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libs imported. Python version is:  3.9.7\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"## SKLEARN\\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.naive_bayes import CategoricalNB, MultinomialNB, GaussianNB\\nfrom sklearn import metrics\\nfrom sklearn.compose import make_column_transformer\\nfrom sklearn.model_selection import KFold\\n\\nimport numpy as np\\n\\nnp.set_printoptions(suppress=True)\\nimport pandas as pd\\nfrom platform import python_version\\n\\nimport scipy\\n\\nimport random\\n\\n# works, sort of only. Possible additional commas that shouldn't be there.\\n%load_ext nb_black\\n\\nprint(\\\"Libs imported. Python version is: \\\", python_version())\";\n",
       "                var nbb_formatted_code = \"## SKLEARN\\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.naive_bayes import CategoricalNB, MultinomialNB, GaussianNB\\nfrom sklearn import metrics\\nfrom sklearn.compose import make_column_transformer\\nfrom sklearn.model_selection import KFold\\n\\nimport numpy as np\\n\\nnp.set_printoptions(suppress=True)\\nimport pandas as pd\\nfrom platform import python_version\\n\\nimport scipy\\n\\nimport random\\n\\n# works, sort of only. Possible additional commas that shouldn't be there.\\n%load_ext nb_black\\n\\nprint(\\\"Libs imported. Python version is: \\\", python_version())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## SKLEARN\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import CategoricalNB, MultinomialNB, GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "import pandas as pd\n",
    "from platform import python_version\n",
    "\n",
    "import scipy\n",
    "\n",
    "import random\n",
    "\n",
    "# works, sort of only. Possible additional commas that shouldn't be there.\n",
    "%load_ext nb_black\n",
    "\n",
    "print(\"Libs imported. Python version is: \", python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a810b851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# utility functions\\n\\ncols_mushroom = [\\n    \\\"labels\\\",\\n    \\\"cap-shape\\\",\\n    \\\"cap-surface\\\",\\n    \\\"cap-color\\\",\\n    \\\"bruises\\\",\\n    \\\"odor\\\",\\n    \\\"gill-attachment\\\",\\n    \\\"gill-spacing\\\",\\n    \\\"gill-size\\\",\\n    \\\"gill-color\\\",\\n    \\\"stalk-shape\\\",\\n    \\\"stalk-root\\\",\\n    \\\"stalk-surface-above-ring\\\",\\n    \\\"stalk-surface-below-ring\\\",\\n    \\\"stalk-color-above-ring\\\",\\n    \\\"stalk-color-below-ring\\\",\\n    \\\"veil-type\\\",\\n    \\\"veil-color\\\",\\n    \\\"ring-number\\\",\\n    \\\"ring-type\\\",\\n    \\\"spore-print-color\\\",\\n    \\\"population\\\",\\n    \\\"habitat\\\",\\n]\\n\\ncols_car = [\\\"buying\\\", \\\"maintenance\\\", \\\"doors\\\", \\\"passengers\\\", \\\"boot\\\", \\\"safety\\\", \\\"labels\\\"]\\n\\ncols_audiology = [\\n    \\\"age_gt_60\\\",\\n    \\\"air\\\",\\n    \\\"airBoneGap\\\",\\n    \\\"ar_c\\\",\\n    \\\"ar_u\\\",\\n    \\\"bone\\\",\\n    \\\"boneAbnormal\\\",\\n    \\\"bser\\\",\\n    \\\"history_buzzing\\\",\\n    \\\"history_dizziness\\\",\\n    \\\"history_fluctuating\\\",\\n    \\\"history_fullness\\\",\\n    \\\"history_heredity\\\",\\n    \\\"history_nausea\\\",\\n    \\\"history_noise\\\",\\n    \\\"history_recruitment\\\",\\n    \\\"history_ringing\\\",\\n    \\\"history_roaring\\\",\\n    \\\"history_vomiting\\\",\\n    \\\"late_wave_poor\\\",\\n    \\\"m_at_2k\\\",\\n    \\\"m_cond_lt_1k\\\",\\n    \\\"m_gt_1k\\\",\\n    \\\"m_m_gt_2k\\\",\\n    \\\"m_m_sn\\\",\\n    \\\"m_m_sn_gt_1k\\\",\\n    \\\"m_m_sn_gt_2k\\\",\\n    \\\"m_m_sn_gt_500\\\",\\n    \\\"m_p_sn_gt_2k\\\",\\n    \\\"m_s_gt_500\\\",\\n    \\\"m_s_sn\\\",\\n    \\\"m_s_sn_gt_1k\\\",\\n    \\\"m_s_sn_gt_2k\\\",\\n    \\\"m_s_sn_gt_3k\\\",\\n    \\\"m_s_sn_gt_4k\\\",\\n    \\\"m_sn_2_3k\\\",\\n    \\\"m_sn_gt_1k\\\",\\n    \\\"m_sn_gt_2k\\\",\\n    \\\"m_sn_gt_3k\\\",\\n    \\\"m_sn_gt_4k\\\",\\n    \\\"m_sn_gt_500\\\",\\n    \\\"m_sn_gt_6k\\\",\\n    \\\"m_sn_lt_1k\\\",\\n    \\\"m_sn_lt_2k\\\",\\n    \\\"m_sn_lt_3k\\\",\\n    \\\"middle_wave_poor\\\",\\n    \\\"mod_gt_4k\\\",\\n    \\\"mod_mixed\\\",\\n    \\\"vmod_s_mixed\\\",\\n    \\\"mod_s_sn_gt_500\\\",\\n    \\\"mod_sn\\\",\\n    \\\"mod_sn_gt_1k\\\",\\n    \\\"mod_sn_gt_2k\\\",\\n    \\\"mod_sn_gt_3k\\\",\\n    \\\"mod_sn_gt_4k\\\",\\n    \\\"mod_sn_gt_500\\\",\\n    \\\"notch_4k\\\",\\n    \\\"notch_at_4k\\\",\\n    \\\"o_ar_c\\\",\\n    \\\"o_ar_u\\\",\\n    \\\"s_sn_gt_1k\\\",\\n    \\\"s_sn_gt_2k\\\",\\n    \\\"s_sn_gt_4k\\\",\\n    \\\"speech\\\",\\n    \\\"static_normal\\\",\\n    \\\"tymp\\\",\\n    \\\"viith_nerve_signs\\\",\\n    \\\"wave_V_delayed\\\",\\n    \\\"waveform_ItoV_prolonged\\\",\\n    \\\"p-index\\\",\\n    \\\"labels\\\",\\n]\\n\\ncols_wine = [\\n    \\\"labels\\\",\\n    \\\"alcohol\\\",\\n    \\\"mallic-acid\\\",\\n    \\\"alcalinity\\\",\\n    \\\"ash\\\",\\n    \\\"magnesium\\\",\\n    \\\"total-phenols\\\",\\n    \\\"flavonids\\\",\\n    \\\"nonflavonid-phenols\\\",\\n    \\\"proanthocyanins\\\",\\n    \\\"color-intensity\\\",\\n    \\\"hue\\\",\\n    \\\"od-of-diluted-wines\\\",\\n    \\\"proline\\\",\\n]\\n\\n\\\"\\\"\\\"\\nhttps://archive.ics.uci.edu/ml/datasets/car+evaluation\\n0-5 -> data\\n6 -> labels\\n\\\"\\\"\\\"\\n\\n\\ndef load_car():\\n    df_car = pd.read_csv(\\n        \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\\\",\\n        header=None,\\n        names=cols_car,\\n    )\\n    # mappings using indexes:\\n    # X = df_car.loc[:, :5].values\\n    # y = df_car.loc[:, 6].values\\n    labels_col = df_car.pop(\\\"labels\\\")\\n    df_car.insert(0, \\\"labels\\\", labels_col)\\n    # replace 5more in doors to 5\\n    # df_car.loc[df_car['doors'] == '5more', 'doors'] = '5'\\n    # df_car[\\\"doors\\\"] = pd.to_numeric(df_car[\\\"doors\\\"])\\n    # replace more in passengers to 5\\n    return df_car\\n\\n\\n\\\"\\\"\\\"\\nhttps://archive.ics.uci.edu/ml/datasets/mushroom\\n1-22 -> data\\n0 -> labels\\n\\\"\\\"\\\"\\n\\n\\ndef load_mushroom():\\n    df_mushroom = pd.read_csv(\\n        \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\\\",\\n        header=None,\\n        names=cols_mushroom,\\n    )\\n    # index mappings\\n    # X = df_mushroom.loc[:, 1:].values\\n    # y = df_mushroom.loc[:, 0].values\\n    return df_mushroom\\n\\n\\n\\\"\\\"\\\"\\nhttps://archive.ics.uci.edu/ml/datasets/Audiology+%28Standardized%29\\n0:length-2 -> data\\nlength-1 unique id (p1-p200)\\nlength -> labels\\n\\\"\\\"\\\"\\n\\n\\ndef load_audiology():\\n    df_audiology = pd.read_csv(\\n        \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/audiology/audiology.standardized.data\\\",\\n        header=None,\\n        names=cols_audiology,\\n    )\\n    # index mapping\\n    # length = len(df_audiology.columns)\\n    # X = df_audiology.loc[:, : length - 3].values\\n    # y = df_audiology.loc[:, length - 1].values\\n    df_audiology = df_audiology.drop(\\\"p-index\\\", axis=1)\\n    labels_col = df_audiology.pop(\\\"labels\\\")\\n    df_audiology.insert(0, \\\"labels\\\", labels_col)\\n    return df_audiology\\n\\n\\n\\\"\\\"\\\"\\nhttps://www.alldatascience.com/classification/wine-dataset-analysis-with-python/\\n1:length -> data\\n0 -> labels\\n\\\"\\\"\\\"\\n\\n\\ndef load_wine():\\n    df_wine = pd.read_csv(\\n        \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\\",\\n        header=None,\\n        names=cols_wine,\\n    )\\n    # index mappings\\n    # length = len(df_wine.columns)\\n    # X = df_wine.loc[:, 1:].values\\n    # y = df_wine.loc[:, 0].values\\n    return df_wine\";\n",
       "                var nbb_formatted_code = \"# utility functions\\n\\ncols_mushroom = [\\n    \\\"labels\\\",\\n    \\\"cap-shape\\\",\\n    \\\"cap-surface\\\",\\n    \\\"cap-color\\\",\\n    \\\"bruises\\\",\\n    \\\"odor\\\",\\n    \\\"gill-attachment\\\",\\n    \\\"gill-spacing\\\",\\n    \\\"gill-size\\\",\\n    \\\"gill-color\\\",\\n    \\\"stalk-shape\\\",\\n    \\\"stalk-root\\\",\\n    \\\"stalk-surface-above-ring\\\",\\n    \\\"stalk-surface-below-ring\\\",\\n    \\\"stalk-color-above-ring\\\",\\n    \\\"stalk-color-below-ring\\\",\\n    \\\"veil-type\\\",\\n    \\\"veil-color\\\",\\n    \\\"ring-number\\\",\\n    \\\"ring-type\\\",\\n    \\\"spore-print-color\\\",\\n    \\\"population\\\",\\n    \\\"habitat\\\",\\n]\\n\\ncols_car = [\\\"buying\\\", \\\"maintenance\\\", \\\"doors\\\", \\\"passengers\\\", \\\"boot\\\", \\\"safety\\\", \\\"labels\\\"]\\n\\ncols_audiology = [\\n    \\\"age_gt_60\\\",\\n    \\\"air\\\",\\n    \\\"airBoneGap\\\",\\n    \\\"ar_c\\\",\\n    \\\"ar_u\\\",\\n    \\\"bone\\\",\\n    \\\"boneAbnormal\\\",\\n    \\\"bser\\\",\\n    \\\"history_buzzing\\\",\\n    \\\"history_dizziness\\\",\\n    \\\"history_fluctuating\\\",\\n    \\\"history_fullness\\\",\\n    \\\"history_heredity\\\",\\n    \\\"history_nausea\\\",\\n    \\\"history_noise\\\",\\n    \\\"history_recruitment\\\",\\n    \\\"history_ringing\\\",\\n    \\\"history_roaring\\\",\\n    \\\"history_vomiting\\\",\\n    \\\"late_wave_poor\\\",\\n    \\\"m_at_2k\\\",\\n    \\\"m_cond_lt_1k\\\",\\n    \\\"m_gt_1k\\\",\\n    \\\"m_m_gt_2k\\\",\\n    \\\"m_m_sn\\\",\\n    \\\"m_m_sn_gt_1k\\\",\\n    \\\"m_m_sn_gt_2k\\\",\\n    \\\"m_m_sn_gt_500\\\",\\n    \\\"m_p_sn_gt_2k\\\",\\n    \\\"m_s_gt_500\\\",\\n    \\\"m_s_sn\\\",\\n    \\\"m_s_sn_gt_1k\\\",\\n    \\\"m_s_sn_gt_2k\\\",\\n    \\\"m_s_sn_gt_3k\\\",\\n    \\\"m_s_sn_gt_4k\\\",\\n    \\\"m_sn_2_3k\\\",\\n    \\\"m_sn_gt_1k\\\",\\n    \\\"m_sn_gt_2k\\\",\\n    \\\"m_sn_gt_3k\\\",\\n    \\\"m_sn_gt_4k\\\",\\n    \\\"m_sn_gt_500\\\",\\n    \\\"m_sn_gt_6k\\\",\\n    \\\"m_sn_lt_1k\\\",\\n    \\\"m_sn_lt_2k\\\",\\n    \\\"m_sn_lt_3k\\\",\\n    \\\"middle_wave_poor\\\",\\n    \\\"mod_gt_4k\\\",\\n    \\\"mod_mixed\\\",\\n    \\\"vmod_s_mixed\\\",\\n    \\\"mod_s_sn_gt_500\\\",\\n    \\\"mod_sn\\\",\\n    \\\"mod_sn_gt_1k\\\",\\n    \\\"mod_sn_gt_2k\\\",\\n    \\\"mod_sn_gt_3k\\\",\\n    \\\"mod_sn_gt_4k\\\",\\n    \\\"mod_sn_gt_500\\\",\\n    \\\"notch_4k\\\",\\n    \\\"notch_at_4k\\\",\\n    \\\"o_ar_c\\\",\\n    \\\"o_ar_u\\\",\\n    \\\"s_sn_gt_1k\\\",\\n    \\\"s_sn_gt_2k\\\",\\n    \\\"s_sn_gt_4k\\\",\\n    \\\"speech\\\",\\n    \\\"static_normal\\\",\\n    \\\"tymp\\\",\\n    \\\"viith_nerve_signs\\\",\\n    \\\"wave_V_delayed\\\",\\n    \\\"waveform_ItoV_prolonged\\\",\\n    \\\"p-index\\\",\\n    \\\"labels\\\",\\n]\\n\\ncols_wine = [\\n    \\\"labels\\\",\\n    \\\"alcohol\\\",\\n    \\\"mallic-acid\\\",\\n    \\\"alcalinity\\\",\\n    \\\"ash\\\",\\n    \\\"magnesium\\\",\\n    \\\"total-phenols\\\",\\n    \\\"flavonids\\\",\\n    \\\"nonflavonid-phenols\\\",\\n    \\\"proanthocyanins\\\",\\n    \\\"color-intensity\\\",\\n    \\\"hue\\\",\\n    \\\"od-of-diluted-wines\\\",\\n    \\\"proline\\\",\\n]\\n\\n\\\"\\\"\\\"\\nhttps://archive.ics.uci.edu/ml/datasets/car+evaluation\\n0-5 -> data\\n6 -> labels\\n\\\"\\\"\\\"\\n\\n\\ndef load_car():\\n    df_car = pd.read_csv(\\n        \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\\\",\\n        header=None,\\n        names=cols_car,\\n    )\\n    # mappings using indexes:\\n    # X = df_car.loc[:, :5].values\\n    # y = df_car.loc[:, 6].values\\n    labels_col = df_car.pop(\\\"labels\\\")\\n    df_car.insert(0, \\\"labels\\\", labels_col)\\n    # replace 5more in doors to 5\\n    # df_car.loc[df_car['doors'] == '5more', 'doors'] = '5'\\n    # df_car[\\\"doors\\\"] = pd.to_numeric(df_car[\\\"doors\\\"])\\n    # replace more in passengers to 5\\n    return df_car\\n\\n\\n\\\"\\\"\\\"\\nhttps://archive.ics.uci.edu/ml/datasets/mushroom\\n1-22 -> data\\n0 -> labels\\n\\\"\\\"\\\"\\n\\n\\ndef load_mushroom():\\n    df_mushroom = pd.read_csv(\\n        \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\\\",\\n        header=None,\\n        names=cols_mushroom,\\n    )\\n    # index mappings\\n    # X = df_mushroom.loc[:, 1:].values\\n    # y = df_mushroom.loc[:, 0].values\\n    return df_mushroom\\n\\n\\n\\\"\\\"\\\"\\nhttps://archive.ics.uci.edu/ml/datasets/Audiology+%28Standardized%29\\n0:length-2 -> data\\nlength-1 unique id (p1-p200)\\nlength -> labels\\n\\\"\\\"\\\"\\n\\n\\ndef load_audiology():\\n    df_audiology = pd.read_csv(\\n        \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/audiology/audiology.standardized.data\\\",\\n        header=None,\\n        names=cols_audiology,\\n    )\\n    # index mapping\\n    # length = len(df_audiology.columns)\\n    # X = df_audiology.loc[:, : length - 3].values\\n    # y = df_audiology.loc[:, length - 1].values\\n    df_audiology = df_audiology.drop(\\\"p-index\\\", axis=1)\\n    labels_col = df_audiology.pop(\\\"labels\\\")\\n    df_audiology.insert(0, \\\"labels\\\", labels_col)\\n    return df_audiology\\n\\n\\n\\\"\\\"\\\"\\nhttps://www.alldatascience.com/classification/wine-dataset-analysis-with-python/\\n1:length -> data\\n0 -> labels\\n\\\"\\\"\\\"\\n\\n\\ndef load_wine():\\n    df_wine = pd.read_csv(\\n        \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\\",\\n        header=None,\\n        names=cols_wine,\\n    )\\n    # index mappings\\n    # length = len(df_wine.columns)\\n    # X = df_wine.loc[:, 1:].values\\n    # y = df_wine.loc[:, 0].values\\n    return df_wine\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# utility functions\n",
    "\n",
    "cols_mushroom = [\n",
    "    \"labels\",\n",
    "    \"cap-shape\",\n",
    "    \"cap-surface\",\n",
    "    \"cap-color\",\n",
    "    \"bruises\",\n",
    "    \"odor\",\n",
    "    \"gill-attachment\",\n",
    "    \"gill-spacing\",\n",
    "    \"gill-size\",\n",
    "    \"gill-color\",\n",
    "    \"stalk-shape\",\n",
    "    \"stalk-root\",\n",
    "    \"stalk-surface-above-ring\",\n",
    "    \"stalk-surface-below-ring\",\n",
    "    \"stalk-color-above-ring\",\n",
    "    \"stalk-color-below-ring\",\n",
    "    \"veil-type\",\n",
    "    \"veil-color\",\n",
    "    \"ring-number\",\n",
    "    \"ring-type\",\n",
    "    \"spore-print-color\",\n",
    "    \"population\",\n",
    "    \"habitat\",\n",
    "]\n",
    "\n",
    "cols_car = [\"buying\", \"maintenance\", \"doors\", \"passengers\", \"boot\", \"safety\", \"labels\"]\n",
    "\n",
    "cols_audiology = [\n",
    "    \"age_gt_60\",\n",
    "    \"air\",\n",
    "    \"airBoneGap\",\n",
    "    \"ar_c\",\n",
    "    \"ar_u\",\n",
    "    \"bone\",\n",
    "    \"boneAbnormal\",\n",
    "    \"bser\",\n",
    "    \"history_buzzing\",\n",
    "    \"history_dizziness\",\n",
    "    \"history_fluctuating\",\n",
    "    \"history_fullness\",\n",
    "    \"history_heredity\",\n",
    "    \"history_nausea\",\n",
    "    \"history_noise\",\n",
    "    \"history_recruitment\",\n",
    "    \"history_ringing\",\n",
    "    \"history_roaring\",\n",
    "    \"history_vomiting\",\n",
    "    \"late_wave_poor\",\n",
    "    \"m_at_2k\",\n",
    "    \"m_cond_lt_1k\",\n",
    "    \"m_gt_1k\",\n",
    "    \"m_m_gt_2k\",\n",
    "    \"m_m_sn\",\n",
    "    \"m_m_sn_gt_1k\",\n",
    "    \"m_m_sn_gt_2k\",\n",
    "    \"m_m_sn_gt_500\",\n",
    "    \"m_p_sn_gt_2k\",\n",
    "    \"m_s_gt_500\",\n",
    "    \"m_s_sn\",\n",
    "    \"m_s_sn_gt_1k\",\n",
    "    \"m_s_sn_gt_2k\",\n",
    "    \"m_s_sn_gt_3k\",\n",
    "    \"m_s_sn_gt_4k\",\n",
    "    \"m_sn_2_3k\",\n",
    "    \"m_sn_gt_1k\",\n",
    "    \"m_sn_gt_2k\",\n",
    "    \"m_sn_gt_3k\",\n",
    "    \"m_sn_gt_4k\",\n",
    "    \"m_sn_gt_500\",\n",
    "    \"m_sn_gt_6k\",\n",
    "    \"m_sn_lt_1k\",\n",
    "    \"m_sn_lt_2k\",\n",
    "    \"m_sn_lt_3k\",\n",
    "    \"middle_wave_poor\",\n",
    "    \"mod_gt_4k\",\n",
    "    \"mod_mixed\",\n",
    "    \"vmod_s_mixed\",\n",
    "    \"mod_s_sn_gt_500\",\n",
    "    \"mod_sn\",\n",
    "    \"mod_sn_gt_1k\",\n",
    "    \"mod_sn_gt_2k\",\n",
    "    \"mod_sn_gt_3k\",\n",
    "    \"mod_sn_gt_4k\",\n",
    "    \"mod_sn_gt_500\",\n",
    "    \"notch_4k\",\n",
    "    \"notch_at_4k\",\n",
    "    \"o_ar_c\",\n",
    "    \"o_ar_u\",\n",
    "    \"s_sn_gt_1k\",\n",
    "    \"s_sn_gt_2k\",\n",
    "    \"s_sn_gt_4k\",\n",
    "    \"speech\",\n",
    "    \"static_normal\",\n",
    "    \"tymp\",\n",
    "    \"viith_nerve_signs\",\n",
    "    \"wave_V_delayed\",\n",
    "    \"waveform_ItoV_prolonged\",\n",
    "    \"p-index\",\n",
    "    \"labels\",\n",
    "]\n",
    "\n",
    "cols_wine = [\n",
    "    \"labels\",\n",
    "    \"alcohol\",\n",
    "    \"mallic-acid\",\n",
    "    \"alcalinity\",\n",
    "    \"ash\",\n",
    "    \"magnesium\",\n",
    "    \"total-phenols\",\n",
    "    \"flavonids\",\n",
    "    \"nonflavonid-phenols\",\n",
    "    \"proanthocyanins\",\n",
    "    \"color-intensity\",\n",
    "    \"hue\",\n",
    "    \"od-of-diluted-wines\",\n",
    "    \"proline\",\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "https://archive.ics.uci.edu/ml/datasets/car+evaluation\n",
    "0-5 -> data\n",
    "6 -> labels\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_car():\n",
    "    df_car = pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\",\n",
    "        header=None,\n",
    "        names=cols_car,\n",
    "    )\n",
    "    # mappings using indexes:\n",
    "    # X = df_car.loc[:, :5].values\n",
    "    # y = df_car.loc[:, 6].values\n",
    "    labels_col = df_car.pop(\"labels\")\n",
    "    df_car.insert(0, \"labels\", labels_col)\n",
    "    # replace 5more in doors to 5\n",
    "    # df_car.loc[df_car['doors'] == '5more', 'doors'] = '5'\n",
    "    # df_car[\"doors\"] = pd.to_numeric(df_car[\"doors\"])\n",
    "    # replace more in passengers to 5\n",
    "    return df_car\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "https://archive.ics.uci.edu/ml/datasets/mushroom\n",
    "1-22 -> data\n",
    "0 -> labels\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_mushroom():\n",
    "    df_mushroom = pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\",\n",
    "        header=None,\n",
    "        names=cols_mushroom,\n",
    "    )\n",
    "    # index mappings\n",
    "    # X = df_mushroom.loc[:, 1:].values\n",
    "    # y = df_mushroom.loc[:, 0].values\n",
    "    return df_mushroom\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "https://archive.ics.uci.edu/ml/datasets/Audiology+%28Standardized%29\n",
    "0:length-2 -> data\n",
    "length-1 unique id (p1-p200)\n",
    "length -> labels\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_audiology():\n",
    "    df_audiology = pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/audiology/audiology.standardized.data\",\n",
    "        header=None,\n",
    "        names=cols_audiology,\n",
    "    )\n",
    "    # index mapping\n",
    "    # length = len(df_audiology.columns)\n",
    "    # X = df_audiology.loc[:, : length - 3].values\n",
    "    # y = df_audiology.loc[:, length - 1].values\n",
    "    df_audiology = df_audiology.drop(\"p-index\", axis=1)\n",
    "    labels_col = df_audiology.pop(\"labels\")\n",
    "    df_audiology.insert(0, \"labels\", labels_col)\n",
    "    return df_audiology\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "https://www.alldatascience.com/classification/wine-dataset-analysis-with-python/\n",
    "1:length -> data\n",
    "0 -> labels\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_wine():\n",
    "    df_wine = pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\",\n",
    "        header=None,\n",
    "        names=cols_wine,\n",
    "    )\n",
    "    # index mappings\n",
    "    # length = len(df_wine.columns)\n",
    "    # X = df_wine.loc[:, 1:].values\n",
    "    # y = df_wine.loc[:, 0].values\n",
    "    return df_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e3ea44b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   labels                    8124 non-null   object\n",
      " 1   cap-shape                 8124 non-null   object\n",
      " 2   cap-surface               8124 non-null   object\n",
      " 3   cap-color                 8124 non-null   object\n",
      " 4   bruises                   8124 non-null   object\n",
      " 5   odor                      8124 non-null   object\n",
      " 6   gill-attachment           8124 non-null   object\n",
      " 7   gill-spacing              8124 non-null   object\n",
      " 8   gill-size                 8124 non-null   object\n",
      " 9   gill-color                8124 non-null   object\n",
      " 10  stalk-shape               8124 non-null   object\n",
      " 11  stalk-root                8124 non-null   object\n",
      " 12  stalk-surface-above-ring  8124 non-null   object\n",
      " 13  stalk-surface-below-ring  8124 non-null   object\n",
      " 14  stalk-color-above-ring    8124 non-null   object\n",
      " 15  stalk-color-below-ring    8124 non-null   object\n",
      " 16  veil-type                 8124 non-null   object\n",
      " 17  veil-color                8124 non-null   object\n",
      " 18  ring-number               8124 non-null   object\n",
      " 19  ring-type                 8124 non-null   object\n",
      " 20  spore-print-color         8124 non-null   object\n",
      " 21  population                8124 non-null   object\n",
      " 22  habitat                   8124 non-null   object\n",
      "dtypes: object(23)\n",
      "memory usage: 1.4+ MB\n",
      "None\n",
      "Size of X:  (8124, 22)\n",
      "Size of y:  (8124,)\n",
      "Size of dataset costs:  (1, 22)\n",
      "Cost of classification on full dataset:  102351\n",
      "Data has been split.\n",
      "Labels encoded:  (6499,) ,  (1625,)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# Choose dataset\\n# dataset = load_car()\\ndataset = load_mushroom()\\n# dataset = load_audiology()\\n### dataset = load_wine() # all cols numerical, doesn't work\\n\\nprint(dataset.info())\\n# print(\\\"First five records:\\\")\\n# print(dataset.head())\\n\\n# Extract to X and y\\nX_cat = dataset.loc[:, dataset.columns != \\\"labels\\\"]\\ny_cat = dataset.loc[:, \\\"labels\\\"]\\n\\nprint(\\\"Size of X: \\\", np.shape(X_cat))\\nprint(\\\"Size of y: \\\", np.shape(y_cat))\\n\\n# Generate a matrix of costs\\nmax_cost_allowed = 10000\\n\\ndataset_costs = pd.DataFrame(\\n    np.random.randint(0, max_cost_allowed, size=(1, np.shape(X_cat)[1])),\\n    columns=X_cat.columns,\\n)\\n\\nprint(\\\"Size of dataset costs: \\\", np.shape(dataset_costs))\\nprint(\\\"Cost of classification on full dataset: \\\", dataset_costs.sum(axis=1)[0])\\n\\nmax_seed_val = 2 ** 32 - 1\\n\\n# Split dataset into training set and test set\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X_cat, y_cat, test_size=0.2, random_state=random.randrange(0, max_seed_val),\\n)\\nprint(\\\"Data has been split.\\\")\\n# print(\\\"X contains features: \\\", X_train.columns == \\\"index\\\")\\n\\n# Transform y using label encoder\\nle = LabelEncoder().fit(y_cat)\\nencoded_y_train = le.transform(y_train)\\nencoded_y_test = le.transform(y_test)\\nprint(\\\"Labels encoded: \\\", np.shape(encoded_y_train), \\\", \\\", np.shape(encoded_y_test))\";\n",
       "                var nbb_formatted_code = \"# Choose dataset\\n# dataset = load_car()\\ndataset = load_mushroom()\\n# dataset = load_audiology()\\n### dataset = load_wine() # all cols numerical, doesn't work\\n\\nprint(dataset.info())\\n# print(\\\"First five records:\\\")\\n# print(dataset.head())\\n\\n# Extract to X and y\\nX_cat = dataset.loc[:, dataset.columns != \\\"labels\\\"]\\ny_cat = dataset.loc[:, \\\"labels\\\"]\\n\\nprint(\\\"Size of X: \\\", np.shape(X_cat))\\nprint(\\\"Size of y: \\\", np.shape(y_cat))\\n\\n# Generate a matrix of costs\\nmax_cost_allowed = 10000\\n\\ndataset_costs = pd.DataFrame(\\n    np.random.randint(0, max_cost_allowed, size=(1, np.shape(X_cat)[1])),\\n    columns=X_cat.columns,\\n)\\n\\nprint(\\\"Size of dataset costs: \\\", np.shape(dataset_costs))\\nprint(\\\"Cost of classification on full dataset: \\\", dataset_costs.sum(axis=1)[0])\\n\\nmax_seed_val = 2 ** 32 - 1\\n\\n# Split dataset into training set and test set\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X_cat, y_cat, test_size=0.2, random_state=random.randrange(0, max_seed_val),\\n)\\nprint(\\\"Data has been split.\\\")\\n# print(\\\"X contains features: \\\", X_train.columns == \\\"index\\\")\\n\\n# Transform y using label encoder\\nle = LabelEncoder().fit(y_cat)\\nencoded_y_train = le.transform(y_train)\\nencoded_y_test = le.transform(y_test)\\nprint(\\\"Labels encoded: \\\", np.shape(encoded_y_train), \\\", \\\", np.shape(encoded_y_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose dataset\n",
    "# dataset = load_car()\n",
    "dataset = load_mushroom()\n",
    "# dataset = load_audiology()\n",
    "### dataset = load_wine() # all cols numerical, doesn't work\n",
    "\n",
    "print(dataset.info())\n",
    "# print(\"First five records:\")\n",
    "# print(dataset.head())\n",
    "\n",
    "# Extract to X and y\n",
    "X_cat = dataset.loc[:, dataset.columns != \"labels\"]\n",
    "y_cat = dataset.loc[:, \"labels\"]\n",
    "\n",
    "print(\"Size of X: \", np.shape(X_cat))\n",
    "print(\"Size of y: \", np.shape(y_cat))\n",
    "\n",
    "# Generate a matrix of costs\n",
    "max_cost_allowed = 10000\n",
    "\n",
    "dataset_costs = pd.DataFrame(\n",
    "    np.random.randint(0, max_cost_allowed, size=(1, np.shape(X_cat)[1])),\n",
    "    columns=X_cat.columns,\n",
    ")\n",
    "\n",
    "print(\"Size of dataset costs: \", np.shape(dataset_costs))\n",
    "print(\"Cost of classification on full dataset: \", dataset_costs.sum(axis=1)[0])\n",
    "\n",
    "max_seed_val = 2 ** 32 - 1\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_cat, y_cat, test_size=0.2, random_state=random.randrange(0, max_seed_val),\n",
    ")\n",
    "print(\"Data has been split.\")\n",
    "# print(\"X contains features: \", X_train.columns == \"index\")\n",
    "\n",
    "# Transform y using label encoder\n",
    "le = LabelEncoder().fit(y_cat)\n",
    "encoded_y_train = le.transform(y_train)\n",
    "encoded_y_test = le.transform(y_test)\n",
    "print(\"Labels encoded: \", np.shape(encoded_y_train), \", \", np.shape(encoded_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba83093b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# Collectors of values\\n\\ncols_one_hot = [\\n    \\\"cap-shape\\\",\\n    \\\"cap-surface\\\",\\n    \\\"cap-color\\\",\\n    \\\"bruises\\\",\\n    \\\"odor\\\",\\n    \\\"gill-attachment\\\",\\n    \\\"gill-spacing\\\",\\n    \\\"gill-size\\\",\\n    \\\"gill-color\\\",\\n    \\\"stalk-shape\\\",\\n    \\\"stalk-root\\\",\\n    \\\"stalk-surface-above-ring\\\",\\n    \\\"stalk-surface-below-ring\\\",\\n    \\\"stalk-color-above-ring\\\",\\n    \\\"stalk-color-below-ring\\\",\\n    \\\"veil-type\\\",\\n    \\\"veil-color\\\",\\n    \\\"ring-number\\\",\\n    \\\"ring-type\\\",\\n    \\\"spore-print-color\\\",\\n    \\\"habitat\\\",\\n    \\\"age_gt_60\\\",\\n    \\\"airBoneGap\\\",\\n    \\\"boneAbnormal\\\",\\n    \\\"history_buzzing\\\",\\n    \\\"history_dizziness\\\",\\n    \\\"history_fluctuating\\\",\\n    \\\"history_fullness\\\",\\n    \\\"history_heredity\\\",\\n    \\\"history_nausea\\\",\\n    \\\"history_noise\\\",\\n    \\\"history_recruitment\\\",\\n    \\\"history_ringing\\\",\\n    \\\"history_roaring\\\",\\n    \\\"history_vomiting\\\",\\n    \\\"late_wave_poor\\\",\\n    \\\"m_at_2k\\\",\\n    \\\"m_cond_lt_1k\\\",\\n    \\\"m_gt_1k\\\",\\n    \\\"m_m_gt_2k\\\",\\n    \\\"m_m_sn\\\",\\n    \\\"m_m_sn_gt_1k\\\",\\n    \\\"m_m_sn_gt_2k\\\",\\n    \\\"m_m_sn_gt_500\\\",\\n    \\\"m_p_sn_gt_2k\\\",\\n    \\\"m_s_gt_500\\\",\\n    \\\"m_s_sn\\\",\\n    \\\"m_s_sn_gt_1k\\\",\\n    \\\"m_s_sn_gt_2k\\\",\\n    \\\"m_s_sn_gt_3k\\\",\\n    \\\"m_s_sn_gt_4k\\\",\\n    \\\"m_sn_2_3k\\\",\\n    \\\"m_sn_gt_1k\\\",\\n    \\\"m_sn_gt_2k\\\",\\n    \\\"m_sn_gt_3k\\\",\\n    \\\"m_sn_gt_4k\\\",\\n    \\\"m_sn_gt_500\\\",\\n    \\\"m_sn_gt_6k\\\",\\n    \\\"m_sn_lt_1k\\\",\\n    \\\"m_sn_lt_2k\\\",\\n    \\\"m_sn_lt_3k\\\",\\n    \\\"middle_wave_poor\\\",\\n    \\\"mod_gt_4k\\\",\\n    \\\"mod_mixed\\\",\\n    \\\"vmod_s_mixed\\\",\\n    \\\"mod_s_sn_gt_500\\\",\\n    \\\"mod_sn\\\",\\n    \\\"mod_sn_gt_1k\\\",\\n    \\\"mod_sn_gt_2k\\\",\\n    \\\"mod_sn_gt_3k\\\",\\n    \\\"mod_sn_gt_4k\\\",\\n    \\\"mod_sn_gt_500\\\",\\n    \\\"notch_4k\\\",\\n    \\\"notch_at_4k\\\",\\n    \\\"s_sn_gt_1k\\\",\\n    \\\"s_sn_gt_2k\\\",\\n    \\\"s_sn_gt_4k\\\",\\n    \\\"static_normal\\\",\\n    \\\"viith_nerve_signs\\\",\\n    \\\"wave_V_delayed\\\",\\n    \\\"waveform_ItoV_prolonged\\\",\\n]\\n\\ncols_ordinal = [\\n    \\\"buying\\\",\\n    \\\"maintenance\\\",\\n    \\\"doors\\\",\\n    \\\"passengers\\\",\\n    \\\"boot\\\",\\n    \\\"safety\\\",\\n    \\\"population\\\",\\n    \\\"air\\\",\\n    \\\"ar_c\\\",\\n    \\\"ar_u\\\",\\n    \\\"bser\\\",\\n    \\\"bone\\\",\\n    \\\"o_ar_c\\\",\\n    \\\"o_ar_u\\\",\\n    \\\"speech\\\",\\n    \\\"tymp\\\",\\n]\";\n",
       "                var nbb_formatted_code = \"# Collectors of values\\n\\ncols_one_hot = [\\n    \\\"cap-shape\\\",\\n    \\\"cap-surface\\\",\\n    \\\"cap-color\\\",\\n    \\\"bruises\\\",\\n    \\\"odor\\\",\\n    \\\"gill-attachment\\\",\\n    \\\"gill-spacing\\\",\\n    \\\"gill-size\\\",\\n    \\\"gill-color\\\",\\n    \\\"stalk-shape\\\",\\n    \\\"stalk-root\\\",\\n    \\\"stalk-surface-above-ring\\\",\\n    \\\"stalk-surface-below-ring\\\",\\n    \\\"stalk-color-above-ring\\\",\\n    \\\"stalk-color-below-ring\\\",\\n    \\\"veil-type\\\",\\n    \\\"veil-color\\\",\\n    \\\"ring-number\\\",\\n    \\\"ring-type\\\",\\n    \\\"spore-print-color\\\",\\n    \\\"habitat\\\",\\n    \\\"age_gt_60\\\",\\n    \\\"airBoneGap\\\",\\n    \\\"boneAbnormal\\\",\\n    \\\"history_buzzing\\\",\\n    \\\"history_dizziness\\\",\\n    \\\"history_fluctuating\\\",\\n    \\\"history_fullness\\\",\\n    \\\"history_heredity\\\",\\n    \\\"history_nausea\\\",\\n    \\\"history_noise\\\",\\n    \\\"history_recruitment\\\",\\n    \\\"history_ringing\\\",\\n    \\\"history_roaring\\\",\\n    \\\"history_vomiting\\\",\\n    \\\"late_wave_poor\\\",\\n    \\\"m_at_2k\\\",\\n    \\\"m_cond_lt_1k\\\",\\n    \\\"m_gt_1k\\\",\\n    \\\"m_m_gt_2k\\\",\\n    \\\"m_m_sn\\\",\\n    \\\"m_m_sn_gt_1k\\\",\\n    \\\"m_m_sn_gt_2k\\\",\\n    \\\"m_m_sn_gt_500\\\",\\n    \\\"m_p_sn_gt_2k\\\",\\n    \\\"m_s_gt_500\\\",\\n    \\\"m_s_sn\\\",\\n    \\\"m_s_sn_gt_1k\\\",\\n    \\\"m_s_sn_gt_2k\\\",\\n    \\\"m_s_sn_gt_3k\\\",\\n    \\\"m_s_sn_gt_4k\\\",\\n    \\\"m_sn_2_3k\\\",\\n    \\\"m_sn_gt_1k\\\",\\n    \\\"m_sn_gt_2k\\\",\\n    \\\"m_sn_gt_3k\\\",\\n    \\\"m_sn_gt_4k\\\",\\n    \\\"m_sn_gt_500\\\",\\n    \\\"m_sn_gt_6k\\\",\\n    \\\"m_sn_lt_1k\\\",\\n    \\\"m_sn_lt_2k\\\",\\n    \\\"m_sn_lt_3k\\\",\\n    \\\"middle_wave_poor\\\",\\n    \\\"mod_gt_4k\\\",\\n    \\\"mod_mixed\\\",\\n    \\\"vmod_s_mixed\\\",\\n    \\\"mod_s_sn_gt_500\\\",\\n    \\\"mod_sn\\\",\\n    \\\"mod_sn_gt_1k\\\",\\n    \\\"mod_sn_gt_2k\\\",\\n    \\\"mod_sn_gt_3k\\\",\\n    \\\"mod_sn_gt_4k\\\",\\n    \\\"mod_sn_gt_500\\\",\\n    \\\"notch_4k\\\",\\n    \\\"notch_at_4k\\\",\\n    \\\"s_sn_gt_1k\\\",\\n    \\\"s_sn_gt_2k\\\",\\n    \\\"s_sn_gt_4k\\\",\\n    \\\"static_normal\\\",\\n    \\\"viith_nerve_signs\\\",\\n    \\\"wave_V_delayed\\\",\\n    \\\"waveform_ItoV_prolonged\\\",\\n]\\n\\ncols_ordinal = [\\n    \\\"buying\\\",\\n    \\\"maintenance\\\",\\n    \\\"doors\\\",\\n    \\\"passengers\\\",\\n    \\\"boot\\\",\\n    \\\"safety\\\",\\n    \\\"population\\\",\\n    \\\"air\\\",\\n    \\\"ar_c\\\",\\n    \\\"ar_u\\\",\\n    \\\"bser\\\",\\n    \\\"bone\\\",\\n    \\\"o_ar_c\\\",\\n    \\\"o_ar_u\\\",\\n    \\\"speech\\\",\\n    \\\"tymp\\\",\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Collectors of values\n",
    "\n",
    "cols_one_hot = [\n",
    "    \"cap-shape\",\n",
    "    \"cap-surface\",\n",
    "    \"cap-color\",\n",
    "    \"bruises\",\n",
    "    \"odor\",\n",
    "    \"gill-attachment\",\n",
    "    \"gill-spacing\",\n",
    "    \"gill-size\",\n",
    "    \"gill-color\",\n",
    "    \"stalk-shape\",\n",
    "    \"stalk-root\",\n",
    "    \"stalk-surface-above-ring\",\n",
    "    \"stalk-surface-below-ring\",\n",
    "    \"stalk-color-above-ring\",\n",
    "    \"stalk-color-below-ring\",\n",
    "    \"veil-type\",\n",
    "    \"veil-color\",\n",
    "    \"ring-number\",\n",
    "    \"ring-type\",\n",
    "    \"spore-print-color\",\n",
    "    \"habitat\",\n",
    "    \"age_gt_60\",\n",
    "    \"airBoneGap\",\n",
    "    \"boneAbnormal\",\n",
    "    \"history_buzzing\",\n",
    "    \"history_dizziness\",\n",
    "    \"history_fluctuating\",\n",
    "    \"history_fullness\",\n",
    "    \"history_heredity\",\n",
    "    \"history_nausea\",\n",
    "    \"history_noise\",\n",
    "    \"history_recruitment\",\n",
    "    \"history_ringing\",\n",
    "    \"history_roaring\",\n",
    "    \"history_vomiting\",\n",
    "    \"late_wave_poor\",\n",
    "    \"m_at_2k\",\n",
    "    \"m_cond_lt_1k\",\n",
    "    \"m_gt_1k\",\n",
    "    \"m_m_gt_2k\",\n",
    "    \"m_m_sn\",\n",
    "    \"m_m_sn_gt_1k\",\n",
    "    \"m_m_sn_gt_2k\",\n",
    "    \"m_m_sn_gt_500\",\n",
    "    \"m_p_sn_gt_2k\",\n",
    "    \"m_s_gt_500\",\n",
    "    \"m_s_sn\",\n",
    "    \"m_s_sn_gt_1k\",\n",
    "    \"m_s_sn_gt_2k\",\n",
    "    \"m_s_sn_gt_3k\",\n",
    "    \"m_s_sn_gt_4k\",\n",
    "    \"m_sn_2_3k\",\n",
    "    \"m_sn_gt_1k\",\n",
    "    \"m_sn_gt_2k\",\n",
    "    \"m_sn_gt_3k\",\n",
    "    \"m_sn_gt_4k\",\n",
    "    \"m_sn_gt_500\",\n",
    "    \"m_sn_gt_6k\",\n",
    "    \"m_sn_lt_1k\",\n",
    "    \"m_sn_lt_2k\",\n",
    "    \"m_sn_lt_3k\",\n",
    "    \"middle_wave_poor\",\n",
    "    \"mod_gt_4k\",\n",
    "    \"mod_mixed\",\n",
    "    \"vmod_s_mixed\",\n",
    "    \"mod_s_sn_gt_500\",\n",
    "    \"mod_sn\",\n",
    "    \"mod_sn_gt_1k\",\n",
    "    \"mod_sn_gt_2k\",\n",
    "    \"mod_sn_gt_3k\",\n",
    "    \"mod_sn_gt_4k\",\n",
    "    \"mod_sn_gt_500\",\n",
    "    \"notch_4k\",\n",
    "    \"notch_at_4k\",\n",
    "    \"s_sn_gt_1k\",\n",
    "    \"s_sn_gt_2k\",\n",
    "    \"s_sn_gt_4k\",\n",
    "    \"static_normal\",\n",
    "    \"viith_nerve_signs\",\n",
    "    \"wave_V_delayed\",\n",
    "    \"waveform_ItoV_prolonged\",\n",
    "]\n",
    "\n",
    "cols_ordinal = [\n",
    "    \"buying\",\n",
    "    \"maintenance\",\n",
    "    \"doors\",\n",
    "    \"passengers\",\n",
    "    \"boot\",\n",
    "    \"safety\",\n",
    "    \"population\",\n",
    "    \"air\",\n",
    "    \"ar_c\",\n",
    "    \"ar_u\",\n",
    "    \"bser\",\n",
    "    \"bone\",\n",
    "    \"o_ar_c\",\n",
    "    \"o_ar_u\",\n",
    "    \"speech\",\n",
    "    \"tymp\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff6bfe05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order created.\n",
      "    buying maintenance    doors passengers     boot   safety population  \\\n",
      "0      low         low        2          2    small      low          y   \n",
      "1      med         med        3          4      med      med          v   \n",
      "2     high        high        4       more      big     high          s   \n",
      "3    vhigh       vhigh    5more    filler1  filler1  filler1          n   \n",
      "4  filler1     filler1  filler1    filler2  filler2  filler2          c   \n",
      "5  filler2     filler2  filler2    filler3  filler3  filler3          a   \n",
      "6  filler3     filler3  filler3    filler4  filler4  filler4    filler1   \n",
      "\n",
      "        air      ar_c      ar_u      bser        bone    o_ar_c    o_ar_u  \\\n",
      "0    normal         ?         ?         ?           ?         ?         ?   \n",
      "1      mild    absent    absent    normal  unmeasured    absent    absent   \n",
      "2  moderate    normal    normal  degraded      normal    normal    normal   \n",
      "3    severe  elevated  elevated   filler1        mild  elevated  elevated   \n",
      "4  profound   filler1   filler1   filler2    moderate   filler1   filler1   \n",
      "5   filler1   filler2   filler2   filler3     filler1   filler2   filler2   \n",
      "6   filler2   filler3   filler3   filler4     filler3   filler3   filler3   \n",
      "\n",
      "       speech     tymp  \n",
      "0           ?        a  \n",
      "1  unmeasured       as  \n",
      "2   very_poor        b  \n",
      "3        poor       ad  \n",
      "4      normal        c  \n",
      "5        good  filler1  \n",
      "6   very_good  filler2  \n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# Make order of categories per each column in ordinal_columns\\norder_of_ordinal_categories = pd.DataFrame.from_dict(\\n    {\\n        \\\"buying\\\": [\\\"low\\\", \\\"med\\\", \\\"high\\\", \\\"vhigh\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"maintenance\\\": [\\\"low\\\", \\\"med\\\", \\\"high\\\", \\\"vhigh\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"doors\\\": [\\\"2\\\", \\\"3\\\", \\\"4\\\", \\\"5more\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"passengers\\\": [\\\"2\\\", \\\"4\\\", \\\"more\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\", \\\"filler4\\\"],\\n        \\\"boot\\\": [\\\"small\\\", \\\"med\\\", \\\"big\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\", \\\"filler4\\\"],\\n        \\\"safety\\\": [\\\"low\\\", \\\"med\\\", \\\"high\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\", \\\"filler4\\\"],\\n        \\\"population\\\": [\\\"y\\\", \\\"v\\\", \\\"s\\\", \\\"n\\\", \\\"c\\\", \\\"a\\\", \\\"filler1\\\"],\\n        \\\"air\\\": [\\n            \\\"normal\\\",\\n            \\\"mild\\\",\\n            \\\"moderate\\\",\\n            \\\"severe\\\",\\n            \\\"profound\\\",\\n            \\\"filler1\\\",\\n            \\\"filler2\\\",\\n        ],\\n        \\\"ar_c\\\": [\\\"?\\\", \\\"absent\\\", \\\"normal\\\", \\\"elevated\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"ar_u\\\": [\\\"?\\\", \\\"absent\\\", \\\"normal\\\", \\\"elevated\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"bser\\\": [\\\"?\\\", \\\"normal\\\", \\\"degraded\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\", \\\"filler4\\\"],\\n        \\\"bone\\\": [\\\"?\\\", \\\"unmeasured\\\", \\\"normal\\\", \\\"mild\\\", \\\"moderate\\\", \\\"filler1\\\", \\\"filler3\\\"],\\n        \\\"o_ar_c\\\": [\\n            \\\"?\\\",\\n            \\\"absent\\\",\\n            \\\"normal\\\",\\n            \\\"elevated\\\",\\n            \\\"filler1\\\",\\n            \\\"filler2\\\",\\n            \\\"filler3\\\",\\n        ],\\n        \\\"o_ar_u\\\": [\\n            \\\"?\\\",\\n            \\\"absent\\\",\\n            \\\"normal\\\",\\n            \\\"elevated\\\",\\n            \\\"filler1\\\",\\n            \\\"filler2\\\",\\n            \\\"filler3\\\",\\n        ],\\n        \\\"speech\\\": [\\n            \\\"?\\\",\\n            \\\"unmeasured\\\",\\n            \\\"very_poor\\\",\\n            \\\"poor\\\",\\n            \\\"normal\\\",\\n            \\\"good\\\",\\n            \\\"very_good\\\",\\n        ],\\n        \\\"tymp\\\": [\\\"a\\\", \\\"as\\\", \\\"b\\\", \\\"ad\\\", \\\"c\\\", \\\"filler1\\\", \\\"filler2\\\"],\\n    }\\n)\\n\\nprint(\\\"Order created.\\\")\\nprint(order_of_ordinal_categories)\";\n",
       "                var nbb_formatted_code = \"# Make order of categories per each column in ordinal_columns\\norder_of_ordinal_categories = pd.DataFrame.from_dict(\\n    {\\n        \\\"buying\\\": [\\\"low\\\", \\\"med\\\", \\\"high\\\", \\\"vhigh\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"maintenance\\\": [\\\"low\\\", \\\"med\\\", \\\"high\\\", \\\"vhigh\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"doors\\\": [\\\"2\\\", \\\"3\\\", \\\"4\\\", \\\"5more\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"passengers\\\": [\\\"2\\\", \\\"4\\\", \\\"more\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\", \\\"filler4\\\"],\\n        \\\"boot\\\": [\\\"small\\\", \\\"med\\\", \\\"big\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\", \\\"filler4\\\"],\\n        \\\"safety\\\": [\\\"low\\\", \\\"med\\\", \\\"high\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\", \\\"filler4\\\"],\\n        \\\"population\\\": [\\\"y\\\", \\\"v\\\", \\\"s\\\", \\\"n\\\", \\\"c\\\", \\\"a\\\", \\\"filler1\\\"],\\n        \\\"air\\\": [\\n            \\\"normal\\\",\\n            \\\"mild\\\",\\n            \\\"moderate\\\",\\n            \\\"severe\\\",\\n            \\\"profound\\\",\\n            \\\"filler1\\\",\\n            \\\"filler2\\\",\\n        ],\\n        \\\"ar_c\\\": [\\\"?\\\", \\\"absent\\\", \\\"normal\\\", \\\"elevated\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"ar_u\\\": [\\\"?\\\", \\\"absent\\\", \\\"normal\\\", \\\"elevated\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"bser\\\": [\\\"?\\\", \\\"normal\\\", \\\"degraded\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\", \\\"filler4\\\"],\\n        \\\"bone\\\": [\\\"?\\\", \\\"unmeasured\\\", \\\"normal\\\", \\\"mild\\\", \\\"moderate\\\", \\\"filler1\\\", \\\"filler3\\\"],\\n        \\\"o_ar_c\\\": [\\n            \\\"?\\\",\\n            \\\"absent\\\",\\n            \\\"normal\\\",\\n            \\\"elevated\\\",\\n            \\\"filler1\\\",\\n            \\\"filler2\\\",\\n            \\\"filler3\\\",\\n        ],\\n        \\\"o_ar_u\\\": [\\n            \\\"?\\\",\\n            \\\"absent\\\",\\n            \\\"normal\\\",\\n            \\\"elevated\\\",\\n            \\\"filler1\\\",\\n            \\\"filler2\\\",\\n            \\\"filler3\\\",\\n        ],\\n        \\\"speech\\\": [\\n            \\\"?\\\",\\n            \\\"unmeasured\\\",\\n            \\\"very_poor\\\",\\n            \\\"poor\\\",\\n            \\\"normal\\\",\\n            \\\"good\\\",\\n            \\\"very_good\\\",\\n        ],\\n        \\\"tymp\\\": [\\\"a\\\", \\\"as\\\", \\\"b\\\", \\\"ad\\\", \\\"c\\\", \\\"filler1\\\", \\\"filler2\\\"],\\n    }\\n)\\n\\nprint(\\\"Order created.\\\")\\nprint(order_of_ordinal_categories)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make order of categories per each column in ordinal_columns\n",
    "order_of_ordinal_categories = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"buying\": [\"low\", \"med\", \"high\", \"vhigh\", \"filler1\", \"filler2\", \"filler3\"],\n",
    "        \"maintenance\": [\"low\", \"med\", \"high\", \"vhigh\", \"filler1\", \"filler2\", \"filler3\"],\n",
    "        \"doors\": [\"2\", \"3\", \"4\", \"5more\", \"filler1\", \"filler2\", \"filler3\"],\n",
    "        \"passengers\": [\"2\", \"4\", \"more\", \"filler1\", \"filler2\", \"filler3\", \"filler4\"],\n",
    "        \"boot\": [\"small\", \"med\", \"big\", \"filler1\", \"filler2\", \"filler3\", \"filler4\"],\n",
    "        \"safety\": [\"low\", \"med\", \"high\", \"filler1\", \"filler2\", \"filler3\", \"filler4\"],\n",
    "        \"population\": [\"y\", \"v\", \"s\", \"n\", \"c\", \"a\", \"filler1\"],\n",
    "        \"air\": [\n",
    "            \"normal\",\n",
    "            \"mild\",\n",
    "            \"moderate\",\n",
    "            \"severe\",\n",
    "            \"profound\",\n",
    "            \"filler1\",\n",
    "            \"filler2\",\n",
    "        ],\n",
    "        \"ar_c\": [\"?\", \"absent\", \"normal\", \"elevated\", \"filler1\", \"filler2\", \"filler3\"],\n",
    "        \"ar_u\": [\"?\", \"absent\", \"normal\", \"elevated\", \"filler1\", \"filler2\", \"filler3\"],\n",
    "        \"bser\": [\"?\", \"normal\", \"degraded\", \"filler1\", \"filler2\", \"filler3\", \"filler4\"],\n",
    "        \"bone\": [\"?\", \"unmeasured\", \"normal\", \"mild\", \"moderate\", \"filler1\", \"filler3\"],\n",
    "        \"o_ar_c\": [\n",
    "            \"?\",\n",
    "            \"absent\",\n",
    "            \"normal\",\n",
    "            \"elevated\",\n",
    "            \"filler1\",\n",
    "            \"filler2\",\n",
    "            \"filler3\",\n",
    "        ],\n",
    "        \"o_ar_u\": [\n",
    "            \"?\",\n",
    "            \"absent\",\n",
    "            \"normal\",\n",
    "            \"elevated\",\n",
    "            \"filler1\",\n",
    "            \"filler2\",\n",
    "            \"filler3\",\n",
    "        ],\n",
    "        \"speech\": [\n",
    "            \"?\",\n",
    "            \"unmeasured\",\n",
    "            \"very_poor\",\n",
    "            \"poor\",\n",
    "            \"normal\",\n",
    "            \"good\",\n",
    "            \"very_good\",\n",
    "        ],\n",
    "        \"tymp\": [\"a\", \"as\", \"b\", \"ad\", \"c\", \"filler1\", \"filler2\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Order created.\")\n",
    "print(order_of_ordinal_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c3c4988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class EncodingCategoricalBayes has been created\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# Create custom encoding categorical bayes classifier\\nclass EncodingCategoricalBayes:\\n    def __init__(\\n        self,\\n        classifier,\\n        ordinal_categories_order,\\n        ordinal_columns,\\n        one_hot_columns,\\n        dataset,\\n    ):\\n        self.classifier = classifier\\n        self.ordinal_categories_order = ordinal_categories_order\\n        self.ordinal_columns = ordinal_columns\\n        self.one_hot_columns = one_hot_columns\\n        self.column_transformer = self.make_column_transformer(dataset).fit(dataset)\\n\\n    def fit(self, X, y):\\n        return self.classifier.fit(self.encode_features(X), y)\\n        # return self.classifier.fit(X, y)\\n\\n    def predict(self, X):\\n        return self.classifier.predict(self.encode_features(X))\\n        # return self.classifier.predict(X)\\n\\n    def predict_proba(self, X):\\n        return self.classifier.predict_proba(self.encode_features(X))\\n        # return self.classifier.predict_proba(X)\\n\\n    def encode_features(self, X):\\n        encoded_X = self.column_transformer.transform(X)\\n        if scipy.sparse.issparse(encoded_X):\\n            encoded_X = encoded_X.toarray()\\n        return encoded_X\\n\\n    def make_column_transformer(self, X):\\n        # Get current ordinal and one hot columns\\n        total_column_list = X.select_dtypes(include=\\\"object\\\").columns\\n        current_columns_one_hot = self.collect_current_one_hot_columns(\\n            total_column_list\\n        )\\n        current_columns_ordinal = self.collect_current_ordinal_columns(\\n            total_column_list\\n        )\\n\\n        current_ordinal_col_ordering_to_encode = self.calculate_current_order_of_ordinal_columns_to_encode(\\n            current_columns_ordinal\\n        )\\n\\n        # Create column transformer\\n        column_transformer = make_column_transformer(\\n            (OneHotEncoder(), current_columns_one_hot),\\n            (\\n                OrdinalEncoder(categories=current_ordinal_col_ordering_to_encode),\\n                current_columns_ordinal,\\n            ),\\n        )\\n        return column_transformer\\n\\n    def calculate_current_order_of_ordinal_columns_to_encode(self, argColumns):\\n        # Get common cols to feed them in proper order to ordinal encoder\\n        index_of_common_cols = self.ordinal_categories_order.columns.intersection(\\n            argColumns\\n        )\\n        # Convert to list\\n        order_of_ordinal_categories_list = (\\n            self.ordinal_categories_order[index_of_common_cols]\\n            .values.transpose()\\n            .tolist()\\n        )\\n        return order_of_ordinal_categories_list\\n\\n    def intersection(self, lst1, lst2):\\n        # collects common elements in both lists\\n        return [value for value in lst1 if value in lst2]\\n\\n    def collect_current_one_hot_columns(self, argCols):\\n        return self.intersection(self.one_hot_columns, argCols)\\n\\n    def collect_current_ordinal_columns(self, argCols):\\n        # make list of all values and create steps for them\\n        return self.intersection(self.ordinal_columns, argCols)\\n\\n    def get_params(self, deep=True):\\n        return self.classifier.get_params()\\n\\n\\nprint(\\\"Class EncodingCategoricalBayes has been created\\\")\";\n",
       "                var nbb_formatted_code = \"# Create custom encoding categorical bayes classifier\\nclass EncodingCategoricalBayes:\\n    def __init__(\\n        self,\\n        classifier,\\n        ordinal_categories_order,\\n        ordinal_columns,\\n        one_hot_columns,\\n        dataset,\\n    ):\\n        self.classifier = classifier\\n        self.ordinal_categories_order = ordinal_categories_order\\n        self.ordinal_columns = ordinal_columns\\n        self.one_hot_columns = one_hot_columns\\n        self.column_transformer = self.make_column_transformer(dataset).fit(dataset)\\n\\n    def fit(self, X, y):\\n        return self.classifier.fit(self.encode_features(X), y)\\n        # return self.classifier.fit(X, y)\\n\\n    def predict(self, X):\\n        return self.classifier.predict(self.encode_features(X))\\n        # return self.classifier.predict(X)\\n\\n    def predict_proba(self, X):\\n        return self.classifier.predict_proba(self.encode_features(X))\\n        # return self.classifier.predict_proba(X)\\n\\n    def encode_features(self, X):\\n        encoded_X = self.column_transformer.transform(X)\\n        if scipy.sparse.issparse(encoded_X):\\n            encoded_X = encoded_X.toarray()\\n        return encoded_X\\n\\n    def make_column_transformer(self, X):\\n        # Get current ordinal and one hot columns\\n        total_column_list = X.select_dtypes(include=\\\"object\\\").columns\\n        current_columns_one_hot = self.collect_current_one_hot_columns(\\n            total_column_list\\n        )\\n        current_columns_ordinal = self.collect_current_ordinal_columns(\\n            total_column_list\\n        )\\n\\n        current_ordinal_col_ordering_to_encode = self.calculate_current_order_of_ordinal_columns_to_encode(\\n            current_columns_ordinal\\n        )\\n\\n        # Create column transformer\\n        column_transformer = make_column_transformer(\\n            (OneHotEncoder(), current_columns_one_hot),\\n            (\\n                OrdinalEncoder(categories=current_ordinal_col_ordering_to_encode),\\n                current_columns_ordinal,\\n            ),\\n        )\\n        return column_transformer\\n\\n    def calculate_current_order_of_ordinal_columns_to_encode(self, argColumns):\\n        # Get common cols to feed them in proper order to ordinal encoder\\n        index_of_common_cols = self.ordinal_categories_order.columns.intersection(\\n            argColumns\\n        )\\n        # Convert to list\\n        order_of_ordinal_categories_list = (\\n            self.ordinal_categories_order[index_of_common_cols]\\n            .values.transpose()\\n            .tolist()\\n        )\\n        return order_of_ordinal_categories_list\\n\\n    def intersection(self, lst1, lst2):\\n        # collects common elements in both lists\\n        return [value for value in lst1 if value in lst2]\\n\\n    def collect_current_one_hot_columns(self, argCols):\\n        return self.intersection(self.one_hot_columns, argCols)\\n\\n    def collect_current_ordinal_columns(self, argCols):\\n        # make list of all values and create steps for them\\n        return self.intersection(self.ordinal_columns, argCols)\\n\\n    def get_params(self, deep=True):\\n        return self.classifier.get_params()\\n\\n\\nprint(\\\"Class EncodingCategoricalBayes has been created\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create custom encoding categorical bayes classifier\n",
    "class EncodingCategoricalBayes:\n",
    "    def __init__(\n",
    "        self,\n",
    "        classifier,\n",
    "        ordinal_categories_order,\n",
    "        ordinal_columns,\n",
    "        one_hot_columns,\n",
    "        dataset,\n",
    "    ):\n",
    "        self.classifier = classifier\n",
    "        self.ordinal_categories_order = ordinal_categories_order\n",
    "        self.ordinal_columns = ordinal_columns\n",
    "        self.one_hot_columns = one_hot_columns\n",
    "        self.column_transformer = self.make_column_transformer(dataset).fit(dataset)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self.classifier.fit(self.encode_features(X), y)\n",
    "        # return self.classifier.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.classifier.predict(self.encode_features(X))\n",
    "        # return self.classifier.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.classifier.predict_proba(self.encode_features(X))\n",
    "        # return self.classifier.predict_proba(X)\n",
    "\n",
    "    def encode_features(self, X):\n",
    "        encoded_X = self.column_transformer.transform(X)\n",
    "        if scipy.sparse.issparse(encoded_X):\n",
    "            encoded_X = encoded_X.toarray()\n",
    "        return encoded_X\n",
    "\n",
    "    def make_column_transformer(self, X):\n",
    "        # Get current ordinal and one hot columns\n",
    "        total_column_list = X.select_dtypes(include=\"object\").columns\n",
    "        current_columns_one_hot = self.collect_current_one_hot_columns(\n",
    "            total_column_list\n",
    "        )\n",
    "        current_columns_ordinal = self.collect_current_ordinal_columns(\n",
    "            total_column_list\n",
    "        )\n",
    "\n",
    "        current_ordinal_col_ordering_to_encode = self.calculate_current_order_of_ordinal_columns_to_encode(\n",
    "            current_columns_ordinal\n",
    "        )\n",
    "\n",
    "        # Create column transformer\n",
    "        column_transformer = make_column_transformer(\n",
    "            (OneHotEncoder(), current_columns_one_hot),\n",
    "            (\n",
    "                OrdinalEncoder(categories=current_ordinal_col_ordering_to_encode),\n",
    "                current_columns_ordinal,\n",
    "            ),\n",
    "        )\n",
    "        return column_transformer\n",
    "\n",
    "    def calculate_current_order_of_ordinal_columns_to_encode(self, argColumns):\n",
    "        # Get common cols to feed them in proper order to ordinal encoder\n",
    "        index_of_common_cols = self.ordinal_categories_order.columns.intersection(\n",
    "            argColumns\n",
    "        )\n",
    "        # Convert to list\n",
    "        order_of_ordinal_categories_list = (\n",
    "            self.ordinal_categories_order[index_of_common_cols]\n",
    "            .values.transpose()\n",
    "            .tolist()\n",
    "        )\n",
    "        return order_of_ordinal_categories_list\n",
    "\n",
    "    def intersection(self, lst1, lst2):\n",
    "        # collects common elements in both lists\n",
    "        return [value for value in lst1 if value in lst2]\n",
    "\n",
    "    def collect_current_one_hot_columns(self, argCols):\n",
    "        return self.intersection(self.one_hot_columns, argCols)\n",
    "\n",
    "    def collect_current_ordinal_columns(self, argCols):\n",
    "        # make list of all values and create steps for them\n",
    "        return self.intersection(self.ordinal_columns, argCols)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return self.classifier.get_params()\n",
    "\n",
    "\n",
    "print(\"Class EncodingCategoricalBayes has been created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36541769",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalNB(min_categories=6499)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# Create a Bayes Classifier || requires min_categories due to a bug with indexes, reporting the bug added to TODO\\nnbayes = CategoricalNB(min_categories=X_train.shape[0])\\n\\nenb = EncodingCategoricalBayes(\\n    classifier=nbayes,\\n    ordinal_categories_order=order_of_ordinal_categories,\\n    ordinal_columns=cols_ordinal,\\n    one_hot_columns=cols_one_hot,\\n    dataset=X_cat,\\n)\\n\\n# Train the model using the training sets\\nenb.fit(X_train, encoded_y_train)\";\n",
       "                var nbb_formatted_code = \"# Create a Bayes Classifier || requires min_categories due to a bug with indexes, reporting the bug added to TODO\\nnbayes = CategoricalNB(min_categories=X_train.shape[0])\\n\\nenb = EncodingCategoricalBayes(\\n    classifier=nbayes,\\n    ordinal_categories_order=order_of_ordinal_categories,\\n    ordinal_columns=cols_ordinal,\\n    one_hot_columns=cols_one_hot,\\n    dataset=X_cat,\\n)\\n\\n# Train the model using the training sets\\nenb.fit(X_train, encoded_y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a Bayes Classifier || requires min_categories due to a bug with indexes, reporting the bug added to TODO\n",
    "nbayes = CategoricalNB(min_categories=X_train.shape[0])\n",
    "\n",
    "enb = EncodingCategoricalBayes(\n",
    "    classifier=nbayes,\n",
    "    ordinal_categories_order=order_of_ordinal_categories,\n",
    "    ordinal_columns=cols_ordinal,\n",
    "    one_hot_columns=cols_one_hot,\n",
    "    dataset=X_cat,\n",
    ")\n",
    "\n",
    "# Train the model using the training sets\n",
    "enb.fit(X_train, encoded_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6583060e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99999999 0.00000001]\n",
      " [0.         1.        ]\n",
      " [1.         0.        ]\n",
      " [1.         0.        ]\n",
      " [1.         0.        ]\n",
      " [1.         0.        ]\n",
      " [1.         0.        ]\n",
      " [1.         0.        ]\n",
      " [0.99999993 0.00000007]\n",
      " [0.99999998 0.00000002]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# Predict the response for test dataset\\ny_pred = le.inverse_transform(enb.predict(X_test))\\ny_pred_probas = enb.predict_proba(X_test)\\nprint(y_pred_probas[0:10])\";\n",
       "                var nbb_formatted_code = \"# Predict the response for test dataset\\ny_pred = le.inverse_transform(enb.predict(X_test))\\ny_pred_probas = enb.predict_proba(X_test)\\nprint(y_pred_probas[0:10])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict the response for test dataset\n",
    "y_pred = le.inverse_transform(enb.predict(X_test))\n",
    "y_pred_probas = enb.predict_proba(X_test)\n",
    "print(y_pred_probas[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d835b50d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.04615384615384 %\n",
      "F1 score: 92.97314320642239 %\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"# Model Accuracy, how often is the classifier correct?\\nprint(\\\"Accuracy:\\\", metrics.accuracy_score(y_test, y_pred) * 100, \\\"%\\\")\\nprint(\\\"F1 score:\\\", metrics.f1_score(y_test, y_pred, average=\\\"weighted\\\") * 100, \\\"%\\\")\";\n",
       "                var nbb_formatted_code = \"# Model Accuracy, how often is the classifier correct?\\nprint(\\\"Accuracy:\\\", metrics.accuracy_score(y_test, y_pred) * 100, \\\"%\\\")\\nprint(\\\"F1 score:\\\", metrics.f1_score(y_test, y_pred, average=\\\"weighted\\\") * 100, \\\"%\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred) * 100, \"%\")\n",
    "print(\"F1 score:\", metrics.f1_score(y_test, y_pred, average=\"weighted\") * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cac59494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification cost per class: 102351\n",
      "Classification cost of all classes: 166320375\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# Get cost of classification\\nclassification_cost = dataset_costs[X_cat.columns].sum(axis=1)[0]\\nprint(\\\"Classification cost per class:\\\", classification_cost)\\nprint(\\\"Classification cost of all classes:\\\", classification_cost * np.shape(X_test)[0])\";\n",
       "                var nbb_formatted_code = \"# Get cost of classification\\nclassification_cost = dataset_costs[X_cat.columns].sum(axis=1)[0]\\nprint(\\\"Classification cost per class:\\\", classification_cost)\\nprint(\\\"Classification cost of all classes:\\\", classification_cost * np.shape(X_test)[0])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get cost of classification\n",
    "classification_cost = dataset_costs[X_cat.columns].sum(axis=1)[0]\n",
    "print(\"Classification cost per class:\", classification_cost)\n",
    "print(\"Classification cost of all classes:\", classification_cost * np.shape(X_test)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
