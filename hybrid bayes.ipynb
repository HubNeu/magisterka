{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e3f0c540",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 133;\n",
       "                var nbb_unformatted_code = \"\\\"\\\"\\\"\\nSolved:\\n    -It's possible for train-test split to split data in such a way, that\\n   after encoding, X_train and X_test have different numbers of features.\\n   Split has to be rerun to fix it. First encode, then split again?\\n   BUT IT STILL HAS TO BE ENCODED AND SPLIT BEFORE STARTING CROSS VALIDATION\\n   AND SEQUENTIAL FEATURE SELECTION. MAYBE APPEND DURING SPLIT AND THEN SPLIT\\n   AGAIN?\\n\\\"\\\"\\\"\\n\\n\\\"\\\"\\\"\\nFishy:\\n    -Improve feature encoding to have proper ordering instead of random numbers\\n    which currently influence classification accuracy:\\n    https://datascience.stackexchange.com/questions/72343/encoding-with-ordinalencoder-how-to-give-levels-as-user-input\\n   \\n   \\n\\\"\\\"\\\"\\n\\\"\\\"\";\n",
       "                var nbb_formatted_code = \"\\\"\\\"\\\"\\nSolved:\\n    -It's possible for train-test split to split data in such a way, that\\n   after encoding, X_train and X_test have different numbers of features.\\n   Split has to be rerun to fix it. First encode, then split again?\\n   BUT IT STILL HAS TO BE ENCODED AND SPLIT BEFORE STARTING CROSS VALIDATION\\n   AND SEQUENTIAL FEATURE SELECTION. MAYBE APPEND DURING SPLIT AND THEN SPLIT\\n   AGAIN?\\n\\\"\\\"\\\"\\n\\n\\\"\\\"\\\"\\nFishy:\\n    -Improve feature encoding to have proper ordering instead of random numbers\\n    which currently influence classification accuracy:\\n    https://datascience.stackexchange.com/questions/72343/encoding-with-ordinalencoder-how-to-give-levels-as-user-input\\n   \\n   \\n\\\"\\\"\\\"\\n\\\"\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Solved:\n",
    "    -It's possible for train-test split to split data in such a way, that\n",
    "   after encoding, X_train and X_test have different numbers of features.\n",
    "   Split has to be rerun to fix it. First encode, then split again?\n",
    "   BUT IT STILL HAS TO BE ENCODED AND SPLIT BEFORE STARTING CROSS VALIDATION\n",
    "   AND SEQUENTIAL FEATURE SELECTION. MAYBE APPEND DURING SPLIT AND THEN SPLIT\n",
    "   AGAIN?\n",
    "    -Improve feature encoding to have proper ordering instead of random numbers\n",
    "    which currently influence classification accuracy:\n",
    "    https://datascience.stackexchange.com/questions/72343/encoding-with-ordinalencoder-how-to-give-levels-as-user-input\n",
    "\n",
    "Fishy:\n",
    "\n",
    "Pickup: \n",
    "    -add missing feature valeus\n",
    "    -classification costs\n",
    "    -sequential feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c628d317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n",
      "Libs imported. Python version is:  3.9.7\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"## SKLEARN\\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.naive_bayes import CategoricalNB, MultinomialNB, GaussianNB\\nfrom sklearn import metrics\\nfrom sklearn.compose import make_column_transformer\\n\\nimport numpy as np\\n\\nnp.set_printoptions(suppress=True)\\nimport pandas as pd\\nfrom platform import python_version\\n\\nimport scipy\\n\\nimport random\\n\\n# works, sort of only. Possible additional commas that shouldn't be there.\\n%load_ext nb_black\\n\\nprint(\\\"Libs imported. Python version is: \\\", python_version())\";\n",
       "                var nbb_formatted_code = \"## SKLEARN\\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.naive_bayes import CategoricalNB, MultinomialNB, GaussianNB\\nfrom sklearn import metrics\\nfrom sklearn.compose import make_column_transformer\\n\\nimport numpy as np\\n\\nnp.set_printoptions(suppress=True)\\nimport pandas as pd\\nfrom platform import python_version\\n\\nimport scipy\\n\\nimport random\\n\\n# works, sort of only. Possible additional commas that shouldn't be there.\\n%load_ext nb_black\\n\\nprint(\\\"Libs imported. Python version is: \\\", python_version())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## SKLEARN\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import CategoricalNB, MultinomialNB, GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "import pandas as pd\n",
    "from platform import python_version\n",
    "\n",
    "import scipy\n",
    "\n",
    "import random\n",
    "\n",
    "# works, sort of only. Possible additional commas that shouldn't be there.\n",
    "%load_ext nb_black\n",
    "\n",
    "print(\"Libs imported. Python version is: \", python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a810b851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "\n",
    "cols_mushroom = [\n",
    "    \"labels\",\n",
    "    \"cap-shape\",\n",
    "    \"cap-surface\",\n",
    "    \"cap-color\",\n",
    "    \"bruises\",\n",
    "    \"odor\",\n",
    "    \"gill-attachment\",\n",
    "    \"gill-spacing\",\n",
    "    \"gill-size\",\n",
    "    \"gill-color\",\n",
    "    \"stalk-shape\",\n",
    "    \"stalk-root\",\n",
    "    \"stalk-surface-above-ring\",\n",
    "    \"stalk-surface-below-ring\",\n",
    "    \"stalk-color-above-ring\",\n",
    "    \"stalk-color-below-ring\",\n",
    "    \"veil-type\",\n",
    "    \"veil-color\",\n",
    "    \"ring-number\",\n",
    "    \"ring-type\",\n",
    "    \"spore-print-color\",\n",
    "    \"population\",\n",
    "    \"habitat\",\n",
    "]\n",
    "\n",
    "cols_car = [\"buying\", \"maintenance\", \"doors\", \"passengers\", \"boot\", \"safety\", \"labels\"]\n",
    "\n",
    "cols_audiology = [\n",
    "    \"age_gt_60\",\n",
    "    \"air\",\n",
    "    \"airBoneGap\",\n",
    "    \"ar_c\",\n",
    "    \"ar_u\",\n",
    "    \"bone\",\n",
    "    \"boneAbnormal\",\n",
    "    \"bser\",\n",
    "    \"history_buzzing\",\n",
    "    \"history_dizziness\",\n",
    "    \"history_fluctuating\",\n",
    "    \"history_fullness\",\n",
    "    \"history_heredity\",\n",
    "    \"history_nausea\",\n",
    "    \"history_noise\",\n",
    "    \"history_recruitment\",\n",
    "    \"history_ringing\",\n",
    "    \"history_roaring\",\n",
    "    \"history_vomiting\",\n",
    "    \"late_wave_poor\",\n",
    "    \"m_at_2k\",\n",
    "    \"m_cond_lt_1k\",\n",
    "    \"m_gt_1k\",\n",
    "    \"m_m_gt_2k\",\n",
    "    \"m_m_sn\",\n",
    "    \"m_m_sn_gt_1k\",\n",
    "    \"m_m_sn_gt_2k\",\n",
    "    \"m_m_sn_gt_500\",\n",
    "    \"m_p_sn_gt_2k\",\n",
    "    \"m_s_gt_500\",\n",
    "    \"m_s_sn\",\n",
    "    \"m_s_sn_gt_1k\",\n",
    "    \"m_s_sn_gt_2k\",\n",
    "    \"m_s_sn_gt_3k\",\n",
    "    \"m_s_sn_gt_4k\",\n",
    "    \"m_sn_2_3k\",\n",
    "    \"m_sn_gt_1k\",\n",
    "    \"m_sn_gt_2k\",\n",
    "    \"m_sn_gt_3k\",\n",
    "    \"m_sn_gt_4k\",\n",
    "    \"m_sn_gt_500\",\n",
    "    \"m_sn_gt_6k\",\n",
    "    \"m_sn_lt_1k\",\n",
    "    \"m_sn_lt_2k\",\n",
    "    \"m_sn_lt_3k\",\n",
    "    \"middle_wave_poor\",\n",
    "    \"mod_gt_4k\",\n",
    "    \"mod_mixed\",\n",
    "    \"vmod_s_mixed\",\n",
    "    \"mod_s_sn_gt_500\",\n",
    "    \"mod_sn\",\n",
    "    \"mod_sn_gt_1k\",\n",
    "    \"mod_sn_gt_2k\",\n",
    "    \"mod_sn_gt_3k\",\n",
    "    \"mod_sn_gt_4k\",\n",
    "    \"mod_sn_gt_500\",\n",
    "    \"notch_4k\",\n",
    "    \"notch_at_4k\",\n",
    "    \"o_ar_c\",\n",
    "    \"o_ar_u\",\n",
    "    \"s_sn_gt_1k\",\n",
    "    \"s_sn_gt_2k\",\n",
    "    \"s_sn_gt_4k\",\n",
    "    \"speech\",\n",
    "    \"static_normal\",\n",
    "    \"tymp\",\n",
    "    \"viith_nerve_signs\",\n",
    "    \"wave_V_delayed\",\n",
    "    \"waveform_ItoV_prolonged\",\n",
    "    \"p-index\",\n",
    "    \"labels\",\n",
    "]\n",
    "\n",
    "cols_wine = [\n",
    "    \"labels\",\n",
    "    \"alcohol\",\n",
    "    \"mallic-acid\",\n",
    "    \"alcalinity\",\n",
    "    \"ash\",\n",
    "    \"magnesium\",\n",
    "    \"total-phenols\",\n",
    "    \"flavonids\",\n",
    "    \"nonflavonid-phenols\",\n",
    "    \"proanthocyanins\",\n",
    "    \"color-intensity\",\n",
    "    \"hue\",\n",
    "    \"od-of-diluted-wines\",\n",
    "    \"proline\",\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "https://archive.ics.uci.edu/ml/datasets/car+evaluation\n",
    "0-5 -> data\n",
    "6 -> labels\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_car():\n",
    "    df_car = pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\",\n",
    "        header=None,\n",
    "        names=cols_car,\n",
    "    )\n",
    "    # mappings using indexes:\n",
    "    # X = df_car.loc[:, :5].values\n",
    "    # y = df_car.loc[:, 6].values\n",
    "    labels_col = df_car.pop(\"labels\")\n",
    "    df_car.insert(0, \"labels\", labels_col)\n",
    "    # replace 5more in doors to 5\n",
    "    # df_car.loc[df_car['doors'] == '5more', 'doors'] = '5'\n",
    "    # df_car[\"doors\"] = pd.to_numeric(df_car[\"doors\"])\n",
    "    # replace more in passengers to 5\n",
    "    return df_car\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "https://archive.ics.uci.edu/ml/datasets/mushroom\n",
    "1-22 -> data\n",
    "0 -> labels\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_mushroom():\n",
    "    df_mushroom = pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\",\n",
    "        header=None,\n",
    "        names=cols_mushroom,\n",
    "    )\n",
    "    # index mappings\n",
    "    # X = df_mushroom.loc[:, 1:].values\n",
    "    # y = df_mushroom.loc[:, 0].values\n",
    "    return df_mushroom\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "https://archive.ics.uci.edu/ml/datasets/Audiology+%28Standardized%29\n",
    "0:length-2 -> data\n",
    "length-1 unique id (p1-p200)\n",
    "length -> labels\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_audiology():\n",
    "    df_audiology = pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/audiology/audiology.standardized.data\",\n",
    "        header=None,\n",
    "        names=cols_audiology,\n",
    "    )\n",
    "    # index mapping\n",
    "    # length = len(df_audiology.columns)\n",
    "    # X = df_audiology.loc[:, : length - 3].values\n",
    "    # y = df_audiology.loc[:, length - 1].values\n",
    "    df_audiology = df_audiology.drop(\"p-index\", axis=1)\n",
    "    labels_col = df_audiology.pop(\"labels\")\n",
    "    df_audiology.insert(0, \"labels\", labels_col)\n",
    "    return df_audiology\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "https://www.alldatascience.com/classification/wine-dataset-analysis-with-python/\n",
    "1:length -> data\n",
    "0 -> labels\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_wine():\n",
    "    df_wine = pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\",\n",
    "        header=None,\n",
    "        names=cols_wine,\n",
    "    )\n",
    "    # index mappings\n",
    "    # length = len(df_wine.columns)\n",
    "    # X = df_wine.loc[:, 1:].values\n",
    "    # y = df_wine.loc[:, 0].values\n",
    "    return df_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0e3ea44b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 70 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   labels                   200 non-null    object\n",
      " 1   age_gt_60                200 non-null    object\n",
      " 2   air                      200 non-null    object\n",
      " 3   airBoneGap               200 non-null    object\n",
      " 4   ar_c                     200 non-null    object\n",
      " 5   ar_u                     200 non-null    object\n",
      " 6   bone                     200 non-null    object\n",
      " 7   boneAbnormal             200 non-null    object\n",
      " 8   bser                     200 non-null    object\n",
      " 9   history_buzzing          200 non-null    object\n",
      " 10  history_dizziness        200 non-null    object\n",
      " 11  history_fluctuating      200 non-null    object\n",
      " 12  history_fullness         200 non-null    object\n",
      " 13  history_heredity         200 non-null    object\n",
      " 14  history_nausea           200 non-null    object\n",
      " 15  history_noise            200 non-null    object\n",
      " 16  history_recruitment      200 non-null    object\n",
      " 17  history_ringing          200 non-null    object\n",
      " 18  history_roaring          200 non-null    object\n",
      " 19  history_vomiting         200 non-null    object\n",
      " 20  late_wave_poor           200 non-null    object\n",
      " 21  m_at_2k                  200 non-null    object\n",
      " 22  m_cond_lt_1k             200 non-null    object\n",
      " 23  m_gt_1k                  200 non-null    object\n",
      " 24  m_m_gt_2k                200 non-null    object\n",
      " 25  m_m_sn                   200 non-null    object\n",
      " 26  m_m_sn_gt_1k             200 non-null    object\n",
      " 27  m_m_sn_gt_2k             200 non-null    object\n",
      " 28  m_m_sn_gt_500            200 non-null    object\n",
      " 29  m_p_sn_gt_2k             200 non-null    object\n",
      " 30  m_s_gt_500               200 non-null    object\n",
      " 31  m_s_sn                   200 non-null    object\n",
      " 32  m_s_sn_gt_1k             200 non-null    object\n",
      " 33  m_s_sn_gt_2k             200 non-null    object\n",
      " 34  m_s_sn_gt_3k             200 non-null    object\n",
      " 35  m_s_sn_gt_4k             200 non-null    object\n",
      " 36  m_sn_2_3k                200 non-null    object\n",
      " 37  m_sn_gt_1k               200 non-null    object\n",
      " 38  m_sn_gt_2k               200 non-null    object\n",
      " 39  m_sn_gt_3k               200 non-null    object\n",
      " 40  m_sn_gt_4k               200 non-null    object\n",
      " 41  m_sn_gt_500              200 non-null    object\n",
      " 42  m_sn_gt_6k               200 non-null    object\n",
      " 43  m_sn_lt_1k               200 non-null    object\n",
      " 44  m_sn_lt_2k               200 non-null    object\n",
      " 45  m_sn_lt_3k               200 non-null    object\n",
      " 46  middle_wave_poor         200 non-null    object\n",
      " 47  mod_gt_4k                200 non-null    object\n",
      " 48  mod_mixed                200 non-null    object\n",
      " 49  vmod_s_mixed             200 non-null    object\n",
      " 50  mod_s_sn_gt_500          200 non-null    object\n",
      " 51  mod_sn                   200 non-null    object\n",
      " 52  mod_sn_gt_1k             200 non-null    object\n",
      " 53  mod_sn_gt_2k             200 non-null    object\n",
      " 54  mod_sn_gt_3k             200 non-null    object\n",
      " 55  mod_sn_gt_4k             200 non-null    object\n",
      " 56  mod_sn_gt_500            200 non-null    object\n",
      " 57  notch_4k                 200 non-null    object\n",
      " 58  notch_at_4k              200 non-null    object\n",
      " 59  o_ar_c                   200 non-null    object\n",
      " 60  o_ar_u                   200 non-null    object\n",
      " 61  s_sn_gt_1k               200 non-null    object\n",
      " 62  s_sn_gt_2k               200 non-null    object\n",
      " 63  s_sn_gt_4k               200 non-null    object\n",
      " 64  speech                   200 non-null    object\n",
      " 65  static_normal            200 non-null    object\n",
      " 66  tymp                     200 non-null    object\n",
      " 67  viith_nerve_signs        200 non-null    object\n",
      " 68  wave_V_delayed           200 non-null    object\n",
      " 69  waveform_ItoV_prolonged  200 non-null    object\n",
      "dtypes: object(70)\n",
      "memory usage: 109.5+ KB\n",
      "None\n",
      "Size of X:  (200, 69)\n",
      "Size of y:  (200,)\n",
      "Size of dataset costs:  (1, 69)\n",
      "Cost of classification on full dataset:  337893\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 78;\n",
       "                var nbb_unformatted_code = \"# Choose dataset\\n# dataset = load_car()\\n# dataset = load_mushroom()\\ndataset = load_audiology()\\n### dataset = load_wine() # all cols numerical, doesn't work\\n\\nprint(dataset.info())\\n# print(\\\"First five records:\\\")\\n# print(dataset.head())\\n\\n# Extract to X and y\\nX_cat = dataset.loc[:, dataset.columns != \\\"labels\\\"]\\ny_cat = dataset.loc[:, \\\"labels\\\"]\\n\\nprint(\\\"Size of X: \\\", np.shape(X_cat))\\nprint(\\\"Size of y: \\\", np.shape(y_cat))\\n\\n# Generate a matrix of costs\\nmax_cost_allowed = 10000\\n\\ndataset_costs = pd.DataFrame(\\n    np.random.randint(0, max_cost_allowed, size=(1, np.shape(X_cat)[1])),\\n    columns=X_cat.columns,\\n)\\n\\nprint(\\\"Size of dataset costs: \\\", np.shape(dataset_costs))\\nprint(\\\"Cost of classification on full dataset: \\\", dataset_costs.sum(axis=1)[0])\";\n",
       "                var nbb_formatted_code = \"# Choose dataset\\n# dataset = load_car()\\n# dataset = load_mushroom()\\ndataset = load_audiology()\\n### dataset = load_wine() # all cols numerical, doesn't work\\n\\nprint(dataset.info())\\n# print(\\\"First five records:\\\")\\n# print(dataset.head())\\n\\n# Extract to X and y\\nX_cat = dataset.loc[:, dataset.columns != \\\"labels\\\"]\\ny_cat = dataset.loc[:, \\\"labels\\\"]\\n\\nprint(\\\"Size of X: \\\", np.shape(X_cat))\\nprint(\\\"Size of y: \\\", np.shape(y_cat))\\n\\n# Generate a matrix of costs\\nmax_cost_allowed = 10000\\n\\ndataset_costs = pd.DataFrame(\\n    np.random.randint(0, max_cost_allowed, size=(1, np.shape(X_cat)[1])),\\n    columns=X_cat.columns,\\n)\\n\\nprint(\\\"Size of dataset costs: \\\", np.shape(dataset_costs))\\nprint(\\\"Cost of classification on full dataset: \\\", dataset_costs.sum(axis=1)[0])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose dataset\n",
    "# dataset = load_car()\n",
    "# dataset = load_mushroom()\n",
    "dataset = load_audiology()\n",
    "### dataset = load_wine() # all cols numerical, doesn't work\n",
    "\n",
    "print(dataset.info())\n",
    "# print(\"First five records:\")\n",
    "# print(dataset.head())\n",
    "\n",
    "# Extract to X and y\n",
    "X_cat = dataset.loc[:, dataset.columns != \"labels\"]\n",
    "y_cat = dataset.loc[:, \"labels\"]\n",
    "\n",
    "print(\"Size of X: \", np.shape(X_cat))\n",
    "print(\"Size of y: \", np.shape(y_cat))\n",
    "\n",
    "# Generate a matrix of costs\n",
    "max_cost_allowed = 10000\n",
    "\n",
    "dataset_costs = pd.DataFrame(\n",
    "    np.random.randint(0, max_cost_allowed, size=(1, np.shape(X_cat)[1])),\n",
    "    columns=X_cat.columns,\n",
    ")\n",
    "\n",
    "print(\"Size of dataset costs: \", np.shape(dataset_costs))\n",
    "print(\"Cost of classification on full dataset: \", dataset_costs.sum(axis=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba83093b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 71;\n",
       "                var nbb_unformatted_code = \"# Collectors of values\\n\\ncols_one_hot = [\\n    \\\"cap-shape\\\",\\n    \\\"cap-surface\\\",\\n    \\\"cap-color\\\",\\n    \\\"bruises\\\",\\n    \\\"odor\\\",\\n    \\\"gill-attachment\\\",\\n    \\\"gill-spacing\\\",\\n    \\\"gill-size\\\",\\n    \\\"gill-color\\\",\\n    \\\"stalk-shape\\\",\\n    \\\"stalk-root\\\",\\n    \\\"stalk-surface-above-ring\\\",\\n    \\\"stalk-surface-below-ring\\\",\\n    \\\"stalk-color-above-ring\\\",\\n    \\\"stalk-color-below-ring\\\",\\n    \\\"veil-type\\\",\\n    \\\"veil-color\\\",\\n    \\\"ring-number\\\",\\n    \\\"ring-type\\\",\\n    \\\"spore-print-color\\\",\\n    \\\"habitat\\\",\\n    \\\"age_gt_60\\\",\\n    \\\"airBoneGap\\\",\\n    \\\"boneAbnormal\\\",\\n    \\\"bser\\\",\\n    \\\"history_buzzing\\\",\\n    \\\"history_dizziness\\\",\\n    \\\"history_fluctuating\\\",\\n    \\\"history_fullness\\\",\\n    \\\"history_heredity\\\",\\n    \\\"history_nausea\\\",\\n    \\\"history_noise\\\",\\n    \\\"history_recruitment\\\",\\n    \\\"history_ringing\\\",\\n    \\\"history_roaring\\\",\\n    \\\"history_vomiting\\\",\\n    \\\"late_wave_poor\\\",\\n    \\\"m_at_2k\\\",\\n    \\\"m_cond_lt_1k\\\",\\n    \\\"m_gt_1k\\\",\\n    \\\"m_m_gt_2k\\\",\\n    \\\"m_m_sn\\\",\\n    \\\"m_m_sn_gt_1k\\\",\\n    \\\"m_m_sn_gt_2k\\\",\\n    \\\"m_m_sn_gt_500\\\",\\n    \\\"m_p_sn_gt_2k\\\",\\n    \\\"m_s_gt_500\\\",\\n    \\\"m_s_sn\\\",\\n    \\\"m_s_sn_gt_1k\\\",\\n    \\\"m_s_sn_gt_2k\\\",\\n    \\\"m_s_sn_gt_3k\\\",\\n    \\\"m_s_sn_gt_4k\\\",\\n    \\\"m_sn_2_3k\\\",\\n    \\\"m_sn_gt_1k\\\",\\n    \\\"m_sn_gt_2k\\\",\\n    \\\"m_sn_gt_3k\\\",\\n    \\\"m_sn_gt_4k\\\",\\n    \\\"m_sn_gt_500\\\",\\n    \\\"m_sn_gt_6k\\\",\\n    \\\"m_sn_lt_1k\\\",\\n    \\\"m_sn_lt_2k\\\",\\n    \\\"m_sn_lt_3k\\\",\\n    \\\"middle_wave_poor\\\",\\n    \\\"mod_gt_4k\\\",\\n    \\\"mod_mixed\\\",\\n    \\\"vmod_s_mixed\\\",\\n    \\\"mod_s_sn_gt_500\\\",\\n    \\\"mod_sn\\\",\\n    \\\"mod_sn_gt_1k\\\",\\n    \\\"mod_sn_gt_2k\\\",\\n    \\\"mod_sn_gt_3k\\\",\\n    \\\"mod_sn_gt_4k\\\",\\n    \\\"mod_sn_gt_500\\\",\\n    \\\"notch_4k\\\",\\n    \\\"notch_at_4k\\\",\\n    \\\"s_sn_gt_1k\\\",\\n    \\\"s_sn_gt_2k\\\",\\n    \\\"s_sn_gt_4k\\\",\\n    \\\"static_normal\\\",\\n    \\\"tymp\\\",\\n    \\\"viith_nerve_signs\\\",\\n    \\\"wave_V_delayed\\\",\\n    \\\"waveform_ItoV_prolonged\\\",\\n]\\n\\ncols_ordinal = [\\n    \\\"buying\\\",\\n    \\\"maintenance\\\",\\n    \\\"doors\\\",\\n    \\\"passengers\\\",\\n    \\\"boot\\\",\\n    \\\"safety\\\",\\n    \\\"population\\\",\\n    \\\"air\\\",\\n    \\\"ar_c\\\",\\n    \\\"ar_u\\\",\\n    \\\"bone\\\",\\n    \\\"o_ar_c\\\",\\n    \\\"o_ar_u\\\",\\n    \\\"speech\\\",\\n]\\n\\n\\ndef intersection(lst1, lst2):\\n    return [value for value in lst1 if value in lst2]\\n\\n\\ndef collect_current_one_hot_columns(argNames):\\n    # make list of all values and create steps for them\\n    return intersection(cols_one_hot, argNames)\\n\\n\\ndef collect_current_ordinal_columns(argNames):\\n    # make list of all values and create steps for them\\n    return intersection(cols_ordinal, argNames)\";\n",
       "                var nbb_formatted_code = \"# Collectors of values\\n\\ncols_one_hot = [\\n    \\\"cap-shape\\\",\\n    \\\"cap-surface\\\",\\n    \\\"cap-color\\\",\\n    \\\"bruises\\\",\\n    \\\"odor\\\",\\n    \\\"gill-attachment\\\",\\n    \\\"gill-spacing\\\",\\n    \\\"gill-size\\\",\\n    \\\"gill-color\\\",\\n    \\\"stalk-shape\\\",\\n    \\\"stalk-root\\\",\\n    \\\"stalk-surface-above-ring\\\",\\n    \\\"stalk-surface-below-ring\\\",\\n    \\\"stalk-color-above-ring\\\",\\n    \\\"stalk-color-below-ring\\\",\\n    \\\"veil-type\\\",\\n    \\\"veil-color\\\",\\n    \\\"ring-number\\\",\\n    \\\"ring-type\\\",\\n    \\\"spore-print-color\\\",\\n    \\\"habitat\\\",\\n    \\\"age_gt_60\\\",\\n    \\\"airBoneGap\\\",\\n    \\\"boneAbnormal\\\",\\n    \\\"bser\\\",\\n    \\\"history_buzzing\\\",\\n    \\\"history_dizziness\\\",\\n    \\\"history_fluctuating\\\",\\n    \\\"history_fullness\\\",\\n    \\\"history_heredity\\\",\\n    \\\"history_nausea\\\",\\n    \\\"history_noise\\\",\\n    \\\"history_recruitment\\\",\\n    \\\"history_ringing\\\",\\n    \\\"history_roaring\\\",\\n    \\\"history_vomiting\\\",\\n    \\\"late_wave_poor\\\",\\n    \\\"m_at_2k\\\",\\n    \\\"m_cond_lt_1k\\\",\\n    \\\"m_gt_1k\\\",\\n    \\\"m_m_gt_2k\\\",\\n    \\\"m_m_sn\\\",\\n    \\\"m_m_sn_gt_1k\\\",\\n    \\\"m_m_sn_gt_2k\\\",\\n    \\\"m_m_sn_gt_500\\\",\\n    \\\"m_p_sn_gt_2k\\\",\\n    \\\"m_s_gt_500\\\",\\n    \\\"m_s_sn\\\",\\n    \\\"m_s_sn_gt_1k\\\",\\n    \\\"m_s_sn_gt_2k\\\",\\n    \\\"m_s_sn_gt_3k\\\",\\n    \\\"m_s_sn_gt_4k\\\",\\n    \\\"m_sn_2_3k\\\",\\n    \\\"m_sn_gt_1k\\\",\\n    \\\"m_sn_gt_2k\\\",\\n    \\\"m_sn_gt_3k\\\",\\n    \\\"m_sn_gt_4k\\\",\\n    \\\"m_sn_gt_500\\\",\\n    \\\"m_sn_gt_6k\\\",\\n    \\\"m_sn_lt_1k\\\",\\n    \\\"m_sn_lt_2k\\\",\\n    \\\"m_sn_lt_3k\\\",\\n    \\\"middle_wave_poor\\\",\\n    \\\"mod_gt_4k\\\",\\n    \\\"mod_mixed\\\",\\n    \\\"vmod_s_mixed\\\",\\n    \\\"mod_s_sn_gt_500\\\",\\n    \\\"mod_sn\\\",\\n    \\\"mod_sn_gt_1k\\\",\\n    \\\"mod_sn_gt_2k\\\",\\n    \\\"mod_sn_gt_3k\\\",\\n    \\\"mod_sn_gt_4k\\\",\\n    \\\"mod_sn_gt_500\\\",\\n    \\\"notch_4k\\\",\\n    \\\"notch_at_4k\\\",\\n    \\\"s_sn_gt_1k\\\",\\n    \\\"s_sn_gt_2k\\\",\\n    \\\"s_sn_gt_4k\\\",\\n    \\\"static_normal\\\",\\n    \\\"tymp\\\",\\n    \\\"viith_nerve_signs\\\",\\n    \\\"wave_V_delayed\\\",\\n    \\\"waveform_ItoV_prolonged\\\",\\n]\\n\\ncols_ordinal = [\\n    \\\"buying\\\",\\n    \\\"maintenance\\\",\\n    \\\"doors\\\",\\n    \\\"passengers\\\",\\n    \\\"boot\\\",\\n    \\\"safety\\\",\\n    \\\"population\\\",\\n    \\\"air\\\",\\n    \\\"ar_c\\\",\\n    \\\"ar_u\\\",\\n    \\\"bone\\\",\\n    \\\"o_ar_c\\\",\\n    \\\"o_ar_u\\\",\\n    \\\"speech\\\",\\n]\\n\\n\\ndef intersection(lst1, lst2):\\n    return [value for value in lst1 if value in lst2]\\n\\n\\ndef collect_current_one_hot_columns(argNames):\\n    # make list of all values and create steps for them\\n    return intersection(cols_one_hot, argNames)\\n\\n\\ndef collect_current_ordinal_columns(argNames):\\n    # make list of all values and create steps for them\\n    return intersection(cols_ordinal, argNames)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Collectors of values\n",
    "\n",
    "cols_one_hot = [\n",
    "    \"cap-shape\",\n",
    "    \"cap-surface\",\n",
    "    \"cap-color\",\n",
    "    \"bruises\",\n",
    "    \"odor\",\n",
    "    \"gill-attachment\",\n",
    "    \"gill-spacing\",\n",
    "    \"gill-size\",\n",
    "    \"gill-color\",\n",
    "    \"stalk-shape\",\n",
    "    \"stalk-root\",\n",
    "    \"stalk-surface-above-ring\",\n",
    "    \"stalk-surface-below-ring\",\n",
    "    \"stalk-color-above-ring\",\n",
    "    \"stalk-color-below-ring\",\n",
    "    \"veil-type\",\n",
    "    \"veil-color\",\n",
    "    \"ring-number\",\n",
    "    \"ring-type\",\n",
    "    \"spore-print-color\",\n",
    "    \"habitat\",\n",
    "    \"age_gt_60\",\n",
    "    \"airBoneGap\",\n",
    "    \"boneAbnormal\",\n",
    "    \"bser\",\n",
    "    \"history_buzzing\",\n",
    "    \"history_dizziness\",\n",
    "    \"history_fluctuating\",\n",
    "    \"history_fullness\",\n",
    "    \"history_heredity\",\n",
    "    \"history_nausea\",\n",
    "    \"history_noise\",\n",
    "    \"history_recruitment\",\n",
    "    \"history_ringing\",\n",
    "    \"history_roaring\",\n",
    "    \"history_vomiting\",\n",
    "    \"late_wave_poor\",\n",
    "    \"m_at_2k\",\n",
    "    \"m_cond_lt_1k\",\n",
    "    \"m_gt_1k\",\n",
    "    \"m_m_gt_2k\",\n",
    "    \"m_m_sn\",\n",
    "    \"m_m_sn_gt_1k\",\n",
    "    \"m_m_sn_gt_2k\",\n",
    "    \"m_m_sn_gt_500\",\n",
    "    \"m_p_sn_gt_2k\",\n",
    "    \"m_s_gt_500\",\n",
    "    \"m_s_sn\",\n",
    "    \"m_s_sn_gt_1k\",\n",
    "    \"m_s_sn_gt_2k\",\n",
    "    \"m_s_sn_gt_3k\",\n",
    "    \"m_s_sn_gt_4k\",\n",
    "    \"m_sn_2_3k\",\n",
    "    \"m_sn_gt_1k\",\n",
    "    \"m_sn_gt_2k\",\n",
    "    \"m_sn_gt_3k\",\n",
    "    \"m_sn_gt_4k\",\n",
    "    \"m_sn_gt_500\",\n",
    "    \"m_sn_gt_6k\",\n",
    "    \"m_sn_lt_1k\",\n",
    "    \"m_sn_lt_2k\",\n",
    "    \"m_sn_lt_3k\",\n",
    "    \"middle_wave_poor\",\n",
    "    \"mod_gt_4k\",\n",
    "    \"mod_mixed\",\n",
    "    \"vmod_s_mixed\",\n",
    "    \"mod_s_sn_gt_500\",\n",
    "    \"mod_sn\",\n",
    "    \"mod_sn_gt_1k\",\n",
    "    \"mod_sn_gt_2k\",\n",
    "    \"mod_sn_gt_3k\",\n",
    "    \"mod_sn_gt_4k\",\n",
    "    \"mod_sn_gt_500\",\n",
    "    \"notch_4k\",\n",
    "    \"notch_at_4k\",\n",
    "    \"s_sn_gt_1k\",\n",
    "    \"s_sn_gt_2k\",\n",
    "    \"s_sn_gt_4k\",\n",
    "    \"static_normal\",\n",
    "    \"tymp\",\n",
    "    \"viith_nerve_signs\",\n",
    "    \"wave_V_delayed\",\n",
    "    \"waveform_ItoV_prolonged\",\n",
    "]\n",
    "\n",
    "cols_ordinal = [\n",
    "    \"buying\",\n",
    "    \"maintenance\",\n",
    "    \"doors\",\n",
    "    \"passengers\",\n",
    "    \"boot\",\n",
    "    \"safety\",\n",
    "    \"population\",\n",
    "    \"air\",\n",
    "    \"ar_c\",\n",
    "    \"ar_u\",\n",
    "    \"bone\",\n",
    "    \"o_ar_c\",\n",
    "    \"o_ar_u\",\n",
    "    \"speech\",\n",
    "]\n",
    "\n",
    "\n",
    "def intersection(lst1, lst2):\n",
    "    return [value for value in lst1 if value in lst2]\n",
    "\n",
    "\n",
    "def collect_current_one_hot_columns(argNames):\n",
    "    # make list of all values and create steps for them\n",
    "    return intersection(cols_one_hot, argNames)\n",
    "\n",
    "\n",
    "def collect_current_ordinal_columns(argNames):\n",
    "    # make list of all values and create steps for them\n",
    "    return intersection(cols_ordinal, argNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ff6bfe05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order created.\n",
      "    buying maintenance    doors passengers     boot   safety population  \\\n",
      "0      low         low        2          2    small      low          y   \n",
      "1      med         med        3          4      med      med          v   \n",
      "2     high        high        4       more      big     high          s   \n",
      "3    vhigh       vhigh    5more    filler1  filler1  filler1          n   \n",
      "4  filler1     filler1  filler1    filler2  filler2  filler2          c   \n",
      "5  filler2     filler2  filler2    filler3  filler3  filler3          a   \n",
      "\n",
      "        air      ar_c      ar_u        bone    o_ar_c    o_ar_u      speech  \n",
      "0    normal    absent    absent  unmeasured    absent    absent  unmeasured  \n",
      "1      mild    normal    normal      normal    normal    normal   very_poor  \n",
      "2  moderate  elevated  elevated        mild  elevated  elevated        poor  \n",
      "3    severe   filler1   filler1    moderate   filler1   filler1      normal  \n",
      "4  profound   filler2   filler2     filler1   filler2   filler2        good  \n",
      "5   filler1   filler3   filler3     filler2   filler3   filler3   very_good  \n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 72;\n",
       "                var nbb_unformatted_code = \"# Make order of categories per each column in ordinal_columns\\norder_of_ordinal_categories = pd.DataFrame.from_dict(\\n    {\\n        \\\"buying\\\": [\\\"low\\\", \\\"med\\\", \\\"high\\\", \\\"vhigh\\\", \\\"filler1\\\", \\\"filler2\\\"],\\n        \\\"maintenance\\\": [\\\"low\\\", \\\"med\\\", \\\"high\\\", \\\"vhigh\\\", \\\"filler1\\\", \\\"filler2\\\"],\\n        \\\"doors\\\": [\\\"2\\\", \\\"3\\\", \\\"4\\\", \\\"5more\\\", \\\"filler1\\\", \\\"filler2\\\"],\\n        \\\"passengers\\\": [\\\"2\\\", \\\"4\\\", \\\"more\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"boot\\\": [\\\"small\\\", \\\"med\\\", \\\"big\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"safety\\\": [\\\"low\\\", \\\"med\\\", \\\"high\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"population\\\": [\\\"y\\\", \\\"v\\\", \\\"s\\\", \\\"n\\\", \\\"c\\\", \\\"a\\\"],\\n        \\\"air\\\": [\\\"normal\\\", \\\"mild\\\", \\\"moderate\\\", \\\"severe\\\", \\\"profound\\\", \\\"filler1\\\"],\\n        \\\"ar_c\\\": [\\\"absent\\\", \\\"normal\\\", \\\"elevated\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"ar_u\\\": [\\\"absent\\\", \\\"normal\\\", \\\"elevated\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"bone\\\": [\\\"unmeasured\\\", \\\"normal\\\", \\\"mild\\\", \\\"moderate\\\", \\\"filler1\\\", \\\"filler2\\\"],\\n        \\\"o_ar_c\\\": [\\\"absent\\\", \\\"normal\\\", \\\"elevated\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"o_ar_u\\\": [\\\"absent\\\", \\\"normal\\\", \\\"elevated\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"speech\\\": [\\\"unmeasured\\\", \\\"very_poor\\\", \\\"poor\\\", \\\"normal\\\", \\\"good\\\", \\\"very_good\\\"],\\n    }\\n)\\n\\nprint(\\\"Order created.\\\")\\nprint(order_of_ordinal_categories)\";\n",
       "                var nbb_formatted_code = \"# Make order of categories per each column in ordinal_columns\\norder_of_ordinal_categories = pd.DataFrame.from_dict(\\n    {\\n        \\\"buying\\\": [\\\"low\\\", \\\"med\\\", \\\"high\\\", \\\"vhigh\\\", \\\"filler1\\\", \\\"filler2\\\"],\\n        \\\"maintenance\\\": [\\\"low\\\", \\\"med\\\", \\\"high\\\", \\\"vhigh\\\", \\\"filler1\\\", \\\"filler2\\\"],\\n        \\\"doors\\\": [\\\"2\\\", \\\"3\\\", \\\"4\\\", \\\"5more\\\", \\\"filler1\\\", \\\"filler2\\\"],\\n        \\\"passengers\\\": [\\\"2\\\", \\\"4\\\", \\\"more\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"boot\\\": [\\\"small\\\", \\\"med\\\", \\\"big\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"safety\\\": [\\\"low\\\", \\\"med\\\", \\\"high\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"population\\\": [\\\"y\\\", \\\"v\\\", \\\"s\\\", \\\"n\\\", \\\"c\\\", \\\"a\\\"],\\n        \\\"air\\\": [\\\"normal\\\", \\\"mild\\\", \\\"moderate\\\", \\\"severe\\\", \\\"profound\\\", \\\"filler1\\\"],\\n        \\\"ar_c\\\": [\\\"absent\\\", \\\"normal\\\", \\\"elevated\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"ar_u\\\": [\\\"absent\\\", \\\"normal\\\", \\\"elevated\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"bone\\\": [\\\"unmeasured\\\", \\\"normal\\\", \\\"mild\\\", \\\"moderate\\\", \\\"filler1\\\", \\\"filler2\\\"],\\n        \\\"o_ar_c\\\": [\\\"absent\\\", \\\"normal\\\", \\\"elevated\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"o_ar_u\\\": [\\\"absent\\\", \\\"normal\\\", \\\"elevated\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"speech\\\": [\\\"unmeasured\\\", \\\"very_poor\\\", \\\"poor\\\", \\\"normal\\\", \\\"good\\\", \\\"very_good\\\"],\\n    }\\n)\\n\\nprint(\\\"Order created.\\\")\\nprint(order_of_ordinal_categories)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make order of categories per each column in ordinal_columns\n",
    "order_of_ordinal_categories = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"buying\": [\"low\", \"med\", \"high\", \"vhigh\", \"filler1\", \"filler2\"],\n",
    "        \"maintenance\": [\"low\", \"med\", \"high\", \"vhigh\", \"filler1\", \"filler2\"],\n",
    "        \"doors\": [\"2\", \"3\", \"4\", \"5more\", \"filler1\", \"filler2\"],\n",
    "        \"passengers\": [\"2\", \"4\", \"more\", \"filler1\", \"filler2\", \"filler3\"],\n",
    "        \"boot\": [\"small\", \"med\", \"big\", \"filler1\", \"filler2\", \"filler3\"],\n",
    "        \"safety\": [\"low\", \"med\", \"high\", \"filler1\", \"filler2\", \"filler3\"],\n",
    "        \"population\": [\"y\", \"v\", \"s\", \"n\", \"c\", \"a\"],\n",
    "        \"air\": [\"normal\", \"mild\", \"moderate\", \"severe\", \"profound\", \"filler1\"],\n",
    "        \"ar_c\": [\"absent\", \"normal\", \"elevated\", \"filler1\", \"filler2\", \"filler3\"],\n",
    "        \"ar_u\": [\"absent\", \"normal\", \"elevated\", \"filler1\", \"filler2\", \"filler3\"],\n",
    "        \"bone\": [\"unmeasured\", \"normal\", \"mild\", \"moderate\", \"filler1\", \"filler2\"],\n",
    "        \"o_ar_c\": [\"absent\", \"normal\", \"elevated\", \"filler1\", \"filler2\", \"filler3\"],\n",
    "        \"o_ar_u\": [\"absent\", \"normal\", \"elevated\", \"filler1\", \"filler2\", \"filler3\"],\n",
    "        \"speech\": [\"unmeasured\", \"very_poor\", \"poor\", \"normal\", \"good\", \"very_good\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Order created.\")\n",
    "print(order_of_ordinal_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1734dfe3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_gt_60 :  ['f' 't']\n",
      "air :  ['mild' 'moderate' 'severe' 'normal' 'profound']\n",
      "airBoneGap :  ['f' 't']\n",
      "ar_c :  ['normal' '?' 'elevated' 'absent']\n",
      "ar_u :  ['normal' 'absent' '?' 'elevated']\n",
      "bone :  ['?' 'mild' 'moderate' 'normal' 'unmeasured']\n",
      "boneAbnormal :  ['t' 'f']\n",
      "bser :  ['?' 'normal' 'degraded']\n",
      "history_buzzing :  ['f' 't']\n",
      "history_dizziness :  ['f' 't']\n",
      "history_fluctuating :  ['f' 't']\n",
      "history_fullness :  ['f' 't']\n",
      "history_heredity :  ['f' 't']\n",
      "history_nausea :  ['f' 't']\n",
      "history_noise :  ['f' 't']\n",
      "history_recruitment :  ['f' 't']\n",
      "history_ringing :  ['f' 't']\n",
      "history_roaring :  ['f' 't']\n",
      "history_vomiting :  ['f' 't']\n",
      "late_wave_poor :  ['f' 't']\n",
      "m_at_2k :  ['f' 't']\n",
      "m_cond_lt_1k :  ['f']\n",
      "m_gt_1k :  ['f' 't']\n",
      "m_m_gt_2k :  ['f' 't']\n",
      "m_m_sn :  ['f' 't']\n",
      "m_m_sn_gt_1k :  ['f' 't']\n",
      "m_m_sn_gt_2k :  ['f' 't']\n",
      "m_m_sn_gt_500 :  ['f' 't']\n",
      "m_p_sn_gt_2k :  ['f']\n",
      "m_s_gt_500 :  ['f' 't']\n",
      "m_s_sn :  ['f' 't']\n",
      "m_s_sn_gt_1k :  ['f']\n",
      "m_s_sn_gt_2k :  ['f' 't']\n",
      "m_s_sn_gt_3k :  ['f' 't']\n",
      "m_s_sn_gt_4k :  ['f' 't']\n",
      "m_sn_2_3k :  ['f' 't']\n",
      "m_sn_gt_1k :  ['f' 't']\n",
      "m_sn_gt_2k :  ['f' 't']\n",
      "m_sn_gt_3k :  ['f' 't']\n",
      "m_sn_gt_4k :  ['f' 't']\n",
      "m_sn_gt_500 :  ['f' 't']\n",
      "m_sn_gt_6k :  ['f']\n",
      "m_sn_lt_1k :  ['f' 't']\n",
      "m_sn_lt_2k :  ['f' 't']\n",
      "m_sn_lt_3k :  ['f' 't']\n",
      "middle_wave_poor :  ['f' 't']\n",
      "mod_gt_4k :  ['f' 't']\n",
      "mod_mixed :  ['f']\n",
      "vmod_s_mixed :  ['f']\n",
      "mod_s_sn_gt_500 :  ['f' 't']\n",
      "mod_sn :  ['f']\n",
      "mod_sn_gt_1k :  ['f' 't']\n",
      "mod_sn_gt_2k :  ['f' 't']\n",
      "mod_sn_gt_3k :  ['f' 't']\n",
      "mod_sn_gt_4k :  ['f' 't']\n",
      "mod_sn_gt_500 :  ['f' 't']\n",
      "notch_4k :  ['f' 't']\n",
      "notch_at_4k :  ['f' 't']\n",
      "o_ar_c :  ['normal' '?' 'elevated' 'absent']\n",
      "o_ar_u :  ['normal' 'absent' '?' 'elevated']\n",
      "s_sn_gt_1k :  ['f' 't']\n",
      "s_sn_gt_2k :  ['f' 't']\n",
      "s_sn_gt_4k :  ['f' 't']\n",
      "speech :  ['normal' 'good' 'very_good' '?' 'very_poor' 'poor' 'unmeasured']\n",
      "static_normal :  ['t' 'f']\n",
      "tymp :  ['a' 'as' 'b' 'ad' 'c']\n",
      "viith_nerve_signs :  ['f' 't']\n",
      "wave_V_delayed :  ['f' 't']\n",
      "waveform_ItoV_prolonged :  ['f' 't']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories ['?'] in column 1 during fit",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16348/4276134564.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# Apply transformation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mencoded_X_cat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_transform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_cat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Successfully encoded dataset.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[1;34m(self, X, y, func, fitted)\u001b[0m\n\u001b[0;32m    432\u001b[0m             self._iter(fitted=fitted, replace_strings=True))\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             return Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[0;32m    435\u001b[0m                 delayed(func)(\n\u001b[0;32m    436\u001b[0m                     \u001b[0mtransformer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfitted\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    777\u001b[0m                             f\"got {self.unknown_value}.\")\n\u001b[0;32m    778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'use_encoded_value'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, handle_unknown, force_all_finite)\u001b[0m\n\u001b[0;32m    107\u001b[0m                         msg = (\"Found unknown categories {0} in column {1}\"\n\u001b[0;32m    108\u001b[0m                                \" during fit\".format(diff, i))\n\u001b[1;32m--> 109\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found unknown categories ['?'] in column 1 during fit"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 80;\n",
       "                var nbb_unformatted_code = \"# Get current ordinal and one hot columns\\ntotal_column_list = X_cat.select_dtypes(include=\\\"object\\\").columns\\ncurrent_columns_one_hot = collect_current_one_hot_columns(total_column_list)\\ncurrent_columns_ordinal = collect_current_ordinal_columns(total_column_list)\\n\\n# Get common cols to feed them in proper order to ordinal encoder\\nindex_of_common_cols = order_of_ordinal_categories.columns.intersection(\\n    current_columns_ordinal\\n)\\n# Convert to list\\norder_of_ordinal_categories_list = (\\n    order_of_ordinal_categories[index_of_common_cols].values.transpose().tolist()\\n)\\n\\n# Encode the columns using one hot and ordinal encoders\\nohe = OneHotEncoder()\\noe = OrdinalEncoder(categories=order_of_ordinal_categories_list)\\n\\nfor col in X_cat:\\n    print(col, \\\": \\\", X_cat[col].unique())\\n\\n# Create column transformer\\ncolumn_transform = make_column_transformer(\\n    (ohe, current_columns_one_hot), (oe, current_columns_ordinal), n_jobs=1\\n)\\n\\n# Apply transformation\\nencoded_X_cat = column_transform.fit_transform(X_cat)\\nprint(\\\"Successfully encoded dataset.\\\")\\n\\n# Transform y using label encoder\\nle = LabelEncoder()\\nencoded_y_cat = le.fit_transform(y_cat)\\nprint(\\\"Successfully encoded dataset labels.\\\")\";\n",
       "                var nbb_formatted_code = \"# Get current ordinal and one hot columns\\ntotal_column_list = X_cat.select_dtypes(include=\\\"object\\\").columns\\ncurrent_columns_one_hot = collect_current_one_hot_columns(total_column_list)\\ncurrent_columns_ordinal = collect_current_ordinal_columns(total_column_list)\\n\\n# Get common cols to feed them in proper order to ordinal encoder\\nindex_of_common_cols = order_of_ordinal_categories.columns.intersection(\\n    current_columns_ordinal\\n)\\n# Convert to list\\norder_of_ordinal_categories_list = (\\n    order_of_ordinal_categories[index_of_common_cols].values.transpose().tolist()\\n)\\n\\n# Encode the columns using one hot and ordinal encoders\\nohe = OneHotEncoder()\\noe = OrdinalEncoder(categories=order_of_ordinal_categories_list)\\n\\nfor col in X_cat:\\n    print(col, \\\": \\\", X_cat[col].unique())\\n\\n# Create column transformer\\ncolumn_transform = make_column_transformer(\\n    (ohe, current_columns_one_hot), (oe, current_columns_ordinal), n_jobs=1\\n)\\n\\n# Apply transformation\\nencoded_X_cat = column_transform.fit_transform(X_cat)\\nprint(\\\"Successfully encoded dataset.\\\")\\n\\n# Transform y using label encoder\\nle = LabelEncoder()\\nencoded_y_cat = le.fit_transform(y_cat)\\nprint(\\\"Successfully encoded dataset labels.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get current ordinal and one hot columns\n",
    "total_column_list = X_cat.select_dtypes(include=\"object\").columns\n",
    "current_columns_one_hot = collect_current_one_hot_columns(total_column_list)\n",
    "current_columns_ordinal = collect_current_ordinal_columns(total_column_list)\n",
    "\n",
    "# Get common cols to feed them in proper order to ordinal encoder\n",
    "index_of_common_cols = order_of_ordinal_categories.columns.intersection(\n",
    "    current_columns_ordinal\n",
    ")\n",
    "# Convert to list\n",
    "order_of_ordinal_categories_list = (\n",
    "    order_of_ordinal_categories[index_of_common_cols].values.transpose().tolist()\n",
    ")\n",
    "\n",
    "# Encode the columns using one hot and ordinal encoders\n",
    "ohe = OneHotEncoder()\n",
    "oe = OrdinalEncoder(categories=order_of_ordinal_categories_list)\n",
    "\n",
    "for col in X_cat:\n",
    "    print(col, \": \", X_cat[col].unique())\n",
    "\n",
    "# Create column transformer\n",
    "column_transform = make_column_transformer(\n",
    "    (ohe, current_columns_one_hot), (oe, current_columns_ordinal), n_jobs=1\n",
    ")\n",
    "\n",
    "# Apply transformation\n",
    "encoded_X_cat = column_transform.fit_transform(X_cat)\n",
    "print(\"Successfully encoded dataset.\")\n",
    "\n",
    "# Transform y using label encoder\n",
    "le = LabelEncoder()\n",
    "encoded_y_cat = le.fit_transform(y_cat)\n",
    "print(\"Successfully encoded dataset labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "99a0f7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been split.\n",
      "Encoded X:  (8124, 112)\n",
      "Train dataset contains  (6499, 112) , y dataset contains  (6499,)\n",
      "Test dataset contains  (1625, 112) , y dataset contains  (1625,)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 75;\n",
       "                var nbb_unformatted_code = \"max_seed_val = 2 ** 32 - 1\\n\\n# Split dataset into training set and test set\\nX_train, X_test, y_train, y_test = train_test_split(\\n    encoded_X_cat,\\n    encoded_y_cat,\\n    test_size=0.2,\\n    random_state=random.randrange(0, max_seed_val),\\n)\\nprint(\\\"Data has been split.\\\")\\n\\nif scipy.sparse.issparse(X_train):\\n    X_train = X_train.toarray()\\nif scipy.sparse.issparse(X_test):\\n    X_test = X_test.toarray()\\n\\nprint(\\\"Encoded X: \\\", np.shape(encoded_X_cat))\\n\\nprint(\\n    \\\"Train dataset contains \\\", X_train.shape, \\\", y dataset contains \\\", y_train.shape,\\n)\\nprint(\\n    \\\"Test dataset contains \\\", X_test.shape, \\\", y dataset contains \\\", y_test.shape,\\n)\";\n",
       "                var nbb_formatted_code = \"max_seed_val = 2 ** 32 - 1\\n\\n# Split dataset into training set and test set\\nX_train, X_test, y_train, y_test = train_test_split(\\n    encoded_X_cat,\\n    encoded_y_cat,\\n    test_size=0.2,\\n    random_state=random.randrange(0, max_seed_val),\\n)\\nprint(\\\"Data has been split.\\\")\\n\\nif scipy.sparse.issparse(X_train):\\n    X_train = X_train.toarray()\\nif scipy.sparse.issparse(X_test):\\n    X_test = X_test.toarray()\\n\\nprint(\\\"Encoded X: \\\", np.shape(encoded_X_cat))\\n\\nprint(\\n    \\\"Train dataset contains \\\", X_train.shape, \\\", y dataset contains \\\", y_train.shape,\\n)\\nprint(\\n    \\\"Test dataset contains \\\", X_test.shape, \\\", y dataset contains \\\", y_test.shape,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_seed_val = 2 ** 32 - 1\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    encoded_X_cat,\n",
    "    encoded_y_cat,\n",
    "    test_size=0.2,\n",
    "    random_state=random.randrange(0, max_seed_val),\n",
    ")\n",
    "print(\"Data has been split.\")\n",
    "\n",
    "if scipy.sparse.issparse(X_train):\n",
    "    X_train = X_train.toarray()\n",
    "if scipy.sparse.issparse(X_test):\n",
    "    X_test = X_test.toarray()\n",
    "\n",
    "print(\"Encoded X: \", np.shape(encoded_X_cat))\n",
    "\n",
    "print(\n",
    "    \"Train dataset contains \", X_train.shape, \", y dataset contains \", y_train.shape,\n",
    ")\n",
    "print(\n",
    "    \"Test dataset contains \", X_test.shape, \", y dataset contains \", y_test.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6583060e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 76;\n",
       "                var nbb_unformatted_code = \"# Create a Bayes Classifier\\nnbayes = CategoricalNB(min_categories=encoded_X_cat.shape[1])\\n\\n# Train the model using the training sets\\nnbayes.fit(X_train, y_train)\\n\\n# Predict the response for test dataset\\ny_pred = nbayes.predict(X_test)\";\n",
       "                var nbb_formatted_code = \"# Create a Bayes Classifier\\nnbayes = CategoricalNB(min_categories=encoded_X_cat.shape[1])\\n\\n# Train the model using the training sets\\nnbayes.fit(X_train, y_train)\\n\\n# Predict the response for test dataset\\ny_pred = nbayes.predict(X_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a Bayes Classifier\n",
    "nbayes = CategoricalNB(min_categories=encoded_X_cat.shape[1])\n",
    "\n",
    "# Train the model using the training sets\n",
    "nbayes.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = nbayes.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d835b50d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.39999999999999 %\n",
      "F1 score: 94.38080895582061 %\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 77;\n",
       "                var nbb_unformatted_code = \"# Model Accuracy, how often is the classifier correct?\\nprint(\\\"Accuracy:\\\", metrics.accuracy_score(y_test, y_pred) * 100, \\\"%\\\")\\nprint(\\\"F1 score:\\\", metrics.f1_score(y_test, y_pred, average=\\\"weighted\\\") * 100, \\\"%\\\")\";\n",
       "                var nbb_formatted_code = \"# Model Accuracy, how often is the classifier correct?\\nprint(\\\"Accuracy:\\\", metrics.accuracy_score(y_test, y_pred) * 100, \\\"%\\\")\\nprint(\\\"F1 score:\\\", metrics.f1_score(y_test, y_pred, average=\\\"weighted\\\") * 100, \\\"%\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred) * 100, \"%\")\n",
    "print(\"F1 score:\", metrics.f1_score(y_test, y_pred, average=\"weighted\") * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac59494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cost of classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b985758",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "useful links:\n",
    "\n",
    "https://dev.to/codinghappinessweb/analysing-dataset-using-naive-bayes-classifier-3d7o\n",
    "https://towardsdatascience.com/15-tips-and-tricks-for-jupyter-notebook-that-will-ease-your-coding-experience-e469207ac95c\n",
    "https://towardsdatascience.com/guide-to-encoding-categorical-features-using-scikit-learn-for-machine-learning-5048997a5c79\n",
    "https://towardsdatascience.com/naive-bayes-classifier-how-to-successfully-use-it-in-python-ecf76a995069\n",
    "https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
