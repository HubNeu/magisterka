{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3f0c540",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (Temp/ipykernel_1480/1084367042.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Hubert\\AppData\\Local\\Temp/ipykernel_1480/1084367042.py\"\u001b[1;36m, line \u001b[1;32m18\u001b[0m\n\u001b[1;33m    -sequential feature selection\u001b[0m\n\u001b[1;37m                                 \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Solved:\n",
    "    -It's possible for train-test split to split data in such a way, that\n",
    "   after encoding, X_train and X_test have different numbers of features.\n",
    "   Split has to be rerun to fix it. First encode, then split again?\n",
    "   BUT IT STILL HAS TO BE ENCODED AND SPLIT BEFORE STARTING CROSS VALIDATION\n",
    "   AND SEQUENTIAL FEATURE SELECTION. MAYBE APPEND DURING SPLIT AND THEN SPLIT\n",
    "   AGAIN?\n",
    "    -Improve feature encoding to have proper ordering instead of random numbers\n",
    "    which currently influence classification accuracy:\n",
    "    https://datascience.stackexchange.com/questions/72343/encoding-with-ordinalencoder-how-to-give-levels-as-user-input\n",
    "\n",
    "Fishy:\n",
    "    -check and check for data leakage (def: https://scikit-learn.org/stable/glossary.html)\n",
    "\n",
    "Pickup: \n",
    "    -that function for gathering columns to encode and putting that into encoders\n",
    "    -wrap encoding and classifier into a class and call it EncodingCategoricalNaiveBayes\n",
    "TODO:\n",
    "    -put the classifier in SFS\n",
    "    -modify SFS to check each predict_proba and stop if threshold is hit\n",
    "    -add cost counting to SFS wrapper\n",
    "    -???\n",
    "    -tests and profit???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c628d317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libs imported. Python version is:  3.9.7\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"## SKLEARN\\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.naive_bayes import CategoricalNB, MultinomialNB, GaussianNB\\nfrom sklearn import metrics\\nfrom sklearn.compose import make_column_transformer\\n\\nimport numpy as np\\n\\nnp.set_printoptions(suppress=True)\\nimport pandas as pd\\nfrom platform import python_version\\n\\nimport scipy\\n\\nimport random\\n\\n# works, sort of only. Possible additional commas that shouldn't be there.\\n%load_ext nb_black\\n\\nprint(\\\"Libs imported. Python version is: \\\", python_version())\";\n",
       "                var nbb_formatted_code = \"## SKLEARN\\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.naive_bayes import CategoricalNB, MultinomialNB, GaussianNB\\nfrom sklearn import metrics\\nfrom sklearn.compose import make_column_transformer\\n\\nimport numpy as np\\n\\nnp.set_printoptions(suppress=True)\\nimport pandas as pd\\nfrom platform import python_version\\n\\nimport scipy\\n\\nimport random\\n\\n# works, sort of only. Possible additional commas that shouldn't be there.\\n%load_ext nb_black\\n\\nprint(\\\"Libs imported. Python version is: \\\", python_version())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## SKLEARN\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import CategoricalNB, MultinomialNB, GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "import pandas as pd\n",
    "from platform import python_version\n",
    "\n",
    "import scipy\n",
    "\n",
    "import random\n",
    "\n",
    "# works, sort of only. Possible additional commas that shouldn't be there.\n",
    "%load_ext nb_black\n",
    "\n",
    "print(\"Libs imported. Python version is: \", python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a810b851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# utility functions\\n\\ncols_mushroom = [\\n    \\\"labels\\\",\\n    \\\"cap-shape\\\",\\n    \\\"cap-surface\\\",\\n    \\\"cap-color\\\",\\n    \\\"bruises\\\",\\n    \\\"odor\\\",\\n    \\\"gill-attachment\\\",\\n    \\\"gill-spacing\\\",\\n    \\\"gill-size\\\",\\n    \\\"gill-color\\\",\\n    \\\"stalk-shape\\\",\\n    \\\"stalk-root\\\",\\n    \\\"stalk-surface-above-ring\\\",\\n    \\\"stalk-surface-below-ring\\\",\\n    \\\"stalk-color-above-ring\\\",\\n    \\\"stalk-color-below-ring\\\",\\n    \\\"veil-type\\\",\\n    \\\"veil-color\\\",\\n    \\\"ring-number\\\",\\n    \\\"ring-type\\\",\\n    \\\"spore-print-color\\\",\\n    \\\"population\\\",\\n    \\\"habitat\\\",\\n]\\n\\ncols_car = [\\\"buying\\\", \\\"maintenance\\\", \\\"doors\\\", \\\"passengers\\\", \\\"boot\\\", \\\"safety\\\", \\\"labels\\\"]\\n\\ncols_audiology = [\\n    \\\"age_gt_60\\\",\\n    \\\"air\\\",\\n    \\\"airBoneGap\\\",\\n    \\\"ar_c\\\",\\n    \\\"ar_u\\\",\\n    \\\"bone\\\",\\n    \\\"boneAbnormal\\\",\\n    \\\"bser\\\",\\n    \\\"history_buzzing\\\",\\n    \\\"history_dizziness\\\",\\n    \\\"history_fluctuating\\\",\\n    \\\"history_fullness\\\",\\n    \\\"history_heredity\\\",\\n    \\\"history_nausea\\\",\\n    \\\"history_noise\\\",\\n    \\\"history_recruitment\\\",\\n    \\\"history_ringing\\\",\\n    \\\"history_roaring\\\",\\n    \\\"history_vomiting\\\",\\n    \\\"late_wave_poor\\\",\\n    \\\"m_at_2k\\\",\\n    \\\"m_cond_lt_1k\\\",\\n    \\\"m_gt_1k\\\",\\n    \\\"m_m_gt_2k\\\",\\n    \\\"m_m_sn\\\",\\n    \\\"m_m_sn_gt_1k\\\",\\n    \\\"m_m_sn_gt_2k\\\",\\n    \\\"m_m_sn_gt_500\\\",\\n    \\\"m_p_sn_gt_2k\\\",\\n    \\\"m_s_gt_500\\\",\\n    \\\"m_s_sn\\\",\\n    \\\"m_s_sn_gt_1k\\\",\\n    \\\"m_s_sn_gt_2k\\\",\\n    \\\"m_s_sn_gt_3k\\\",\\n    \\\"m_s_sn_gt_4k\\\",\\n    \\\"m_sn_2_3k\\\",\\n    \\\"m_sn_gt_1k\\\",\\n    \\\"m_sn_gt_2k\\\",\\n    \\\"m_sn_gt_3k\\\",\\n    \\\"m_sn_gt_4k\\\",\\n    \\\"m_sn_gt_500\\\",\\n    \\\"m_sn_gt_6k\\\",\\n    \\\"m_sn_lt_1k\\\",\\n    \\\"m_sn_lt_2k\\\",\\n    \\\"m_sn_lt_3k\\\",\\n    \\\"middle_wave_poor\\\",\\n    \\\"mod_gt_4k\\\",\\n    \\\"mod_mixed\\\",\\n    \\\"vmod_s_mixed\\\",\\n    \\\"mod_s_sn_gt_500\\\",\\n    \\\"mod_sn\\\",\\n    \\\"mod_sn_gt_1k\\\",\\n    \\\"mod_sn_gt_2k\\\",\\n    \\\"mod_sn_gt_3k\\\",\\n    \\\"mod_sn_gt_4k\\\",\\n    \\\"mod_sn_gt_500\\\",\\n    \\\"notch_4k\\\",\\n    \\\"notch_at_4k\\\",\\n    \\\"o_ar_c\\\",\\n    \\\"o_ar_u\\\",\\n    \\\"s_sn_gt_1k\\\",\\n    \\\"s_sn_gt_2k\\\",\\n    \\\"s_sn_gt_4k\\\",\\n    \\\"speech\\\",\\n    \\\"static_normal\\\",\\n    \\\"tymp\\\",\\n    \\\"viith_nerve_signs\\\",\\n    \\\"wave_V_delayed\\\",\\n    \\\"waveform_ItoV_prolonged\\\",\\n    \\\"p-index\\\",\\n    \\\"labels\\\",\\n]\\n\\ncols_wine = [\\n    \\\"labels\\\",\\n    \\\"alcohol\\\",\\n    \\\"mallic-acid\\\",\\n    \\\"alcalinity\\\",\\n    \\\"ash\\\",\\n    \\\"magnesium\\\",\\n    \\\"total-phenols\\\",\\n    \\\"flavonids\\\",\\n    \\\"nonflavonid-phenols\\\",\\n    \\\"proanthocyanins\\\",\\n    \\\"color-intensity\\\",\\n    \\\"hue\\\",\\n    \\\"od-of-diluted-wines\\\",\\n    \\\"proline\\\",\\n]\\n\\n\\\"\\\"\\\"\\nhttps://archive.ics.uci.edu/ml/datasets/car+evaluation\\n0-5 -> data\\n6 -> labels\\n\\\"\\\"\\\"\\n\\n\\ndef load_car():\\n    df_car = pd.read_csv(\\n        \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\\\",\\n        header=None,\\n        names=cols_car,\\n    )\\n    # mappings using indexes:\\n    # X = df_car.loc[:, :5].values\\n    # y = df_car.loc[:, 6].values\\n    labels_col = df_car.pop(\\\"labels\\\")\\n    df_car.insert(0, \\\"labels\\\", labels_col)\\n    # replace 5more in doors to 5\\n    # df_car.loc[df_car['doors'] == '5more', 'doors'] = '5'\\n    # df_car[\\\"doors\\\"] = pd.to_numeric(df_car[\\\"doors\\\"])\\n    # replace more in passengers to 5\\n    return df_car\\n\\n\\n\\\"\\\"\\\"\\nhttps://archive.ics.uci.edu/ml/datasets/mushroom\\n1-22 -> data\\n0 -> labels\\n\\\"\\\"\\\"\\n\\n\\ndef load_mushroom():\\n    df_mushroom = pd.read_csv(\\n        \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\\\",\\n        header=None,\\n        names=cols_mushroom,\\n    )\\n    # index mappings\\n    # X = df_mushroom.loc[:, 1:].values\\n    # y = df_mushroom.loc[:, 0].values\\n    return df_mushroom\\n\\n\\n\\\"\\\"\\\"\\nhttps://archive.ics.uci.edu/ml/datasets/Audiology+%28Standardized%29\\n0:length-2 -> data\\nlength-1 unique id (p1-p200)\\nlength -> labels\\n\\\"\\\"\\\"\\n\\n\\ndef load_audiology():\\n    df_audiology = pd.read_csv(\\n        \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/audiology/audiology.standardized.data\\\",\\n        header=None,\\n        names=cols_audiology,\\n    )\\n    # index mapping\\n    # length = len(df_audiology.columns)\\n    # X = df_audiology.loc[:, : length - 3].values\\n    # y = df_audiology.loc[:, length - 1].values\\n    df_audiology = df_audiology.drop(\\\"p-index\\\", axis=1)\\n    labels_col = df_audiology.pop(\\\"labels\\\")\\n    df_audiology.insert(0, \\\"labels\\\", labels_col)\\n    return df_audiology\\n\\n\\n\\\"\\\"\\\"\\nhttps://www.alldatascience.com/classification/wine-dataset-analysis-with-python/\\n1:length -> data\\n0 -> labels\\n\\\"\\\"\\\"\\n\\n\\ndef load_wine():\\n    df_wine = pd.read_csv(\\n        \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\\",\\n        header=None,\\n        names=cols_wine,\\n    )\\n    # index mappings\\n    # length = len(df_wine.columns)\\n    # X = df_wine.loc[:, 1:].values\\n    # y = df_wine.loc[:, 0].values\\n    return df_wine\";\n",
       "                var nbb_formatted_code = \"# utility functions\\n\\ncols_mushroom = [\\n    \\\"labels\\\",\\n    \\\"cap-shape\\\",\\n    \\\"cap-surface\\\",\\n    \\\"cap-color\\\",\\n    \\\"bruises\\\",\\n    \\\"odor\\\",\\n    \\\"gill-attachment\\\",\\n    \\\"gill-spacing\\\",\\n    \\\"gill-size\\\",\\n    \\\"gill-color\\\",\\n    \\\"stalk-shape\\\",\\n    \\\"stalk-root\\\",\\n    \\\"stalk-surface-above-ring\\\",\\n    \\\"stalk-surface-below-ring\\\",\\n    \\\"stalk-color-above-ring\\\",\\n    \\\"stalk-color-below-ring\\\",\\n    \\\"veil-type\\\",\\n    \\\"veil-color\\\",\\n    \\\"ring-number\\\",\\n    \\\"ring-type\\\",\\n    \\\"spore-print-color\\\",\\n    \\\"population\\\",\\n    \\\"habitat\\\",\\n]\\n\\ncols_car = [\\\"buying\\\", \\\"maintenance\\\", \\\"doors\\\", \\\"passengers\\\", \\\"boot\\\", \\\"safety\\\", \\\"labels\\\"]\\n\\ncols_audiology = [\\n    \\\"age_gt_60\\\",\\n    \\\"air\\\",\\n    \\\"airBoneGap\\\",\\n    \\\"ar_c\\\",\\n    \\\"ar_u\\\",\\n    \\\"bone\\\",\\n    \\\"boneAbnormal\\\",\\n    \\\"bser\\\",\\n    \\\"history_buzzing\\\",\\n    \\\"history_dizziness\\\",\\n    \\\"history_fluctuating\\\",\\n    \\\"history_fullness\\\",\\n    \\\"history_heredity\\\",\\n    \\\"history_nausea\\\",\\n    \\\"history_noise\\\",\\n    \\\"history_recruitment\\\",\\n    \\\"history_ringing\\\",\\n    \\\"history_roaring\\\",\\n    \\\"history_vomiting\\\",\\n    \\\"late_wave_poor\\\",\\n    \\\"m_at_2k\\\",\\n    \\\"m_cond_lt_1k\\\",\\n    \\\"m_gt_1k\\\",\\n    \\\"m_m_gt_2k\\\",\\n    \\\"m_m_sn\\\",\\n    \\\"m_m_sn_gt_1k\\\",\\n    \\\"m_m_sn_gt_2k\\\",\\n    \\\"m_m_sn_gt_500\\\",\\n    \\\"m_p_sn_gt_2k\\\",\\n    \\\"m_s_gt_500\\\",\\n    \\\"m_s_sn\\\",\\n    \\\"m_s_sn_gt_1k\\\",\\n    \\\"m_s_sn_gt_2k\\\",\\n    \\\"m_s_sn_gt_3k\\\",\\n    \\\"m_s_sn_gt_4k\\\",\\n    \\\"m_sn_2_3k\\\",\\n    \\\"m_sn_gt_1k\\\",\\n    \\\"m_sn_gt_2k\\\",\\n    \\\"m_sn_gt_3k\\\",\\n    \\\"m_sn_gt_4k\\\",\\n    \\\"m_sn_gt_500\\\",\\n    \\\"m_sn_gt_6k\\\",\\n    \\\"m_sn_lt_1k\\\",\\n    \\\"m_sn_lt_2k\\\",\\n    \\\"m_sn_lt_3k\\\",\\n    \\\"middle_wave_poor\\\",\\n    \\\"mod_gt_4k\\\",\\n    \\\"mod_mixed\\\",\\n    \\\"vmod_s_mixed\\\",\\n    \\\"mod_s_sn_gt_500\\\",\\n    \\\"mod_sn\\\",\\n    \\\"mod_sn_gt_1k\\\",\\n    \\\"mod_sn_gt_2k\\\",\\n    \\\"mod_sn_gt_3k\\\",\\n    \\\"mod_sn_gt_4k\\\",\\n    \\\"mod_sn_gt_500\\\",\\n    \\\"notch_4k\\\",\\n    \\\"notch_at_4k\\\",\\n    \\\"o_ar_c\\\",\\n    \\\"o_ar_u\\\",\\n    \\\"s_sn_gt_1k\\\",\\n    \\\"s_sn_gt_2k\\\",\\n    \\\"s_sn_gt_4k\\\",\\n    \\\"speech\\\",\\n    \\\"static_normal\\\",\\n    \\\"tymp\\\",\\n    \\\"viith_nerve_signs\\\",\\n    \\\"wave_V_delayed\\\",\\n    \\\"waveform_ItoV_prolonged\\\",\\n    \\\"p-index\\\",\\n    \\\"labels\\\",\\n]\\n\\ncols_wine = [\\n    \\\"labels\\\",\\n    \\\"alcohol\\\",\\n    \\\"mallic-acid\\\",\\n    \\\"alcalinity\\\",\\n    \\\"ash\\\",\\n    \\\"magnesium\\\",\\n    \\\"total-phenols\\\",\\n    \\\"flavonids\\\",\\n    \\\"nonflavonid-phenols\\\",\\n    \\\"proanthocyanins\\\",\\n    \\\"color-intensity\\\",\\n    \\\"hue\\\",\\n    \\\"od-of-diluted-wines\\\",\\n    \\\"proline\\\",\\n]\\n\\n\\\"\\\"\\\"\\nhttps://archive.ics.uci.edu/ml/datasets/car+evaluation\\n0-5 -> data\\n6 -> labels\\n\\\"\\\"\\\"\\n\\n\\ndef load_car():\\n    df_car = pd.read_csv(\\n        \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\\\",\\n        header=None,\\n        names=cols_car,\\n    )\\n    # mappings using indexes:\\n    # X = df_car.loc[:, :5].values\\n    # y = df_car.loc[:, 6].values\\n    labels_col = df_car.pop(\\\"labels\\\")\\n    df_car.insert(0, \\\"labels\\\", labels_col)\\n    # replace 5more in doors to 5\\n    # df_car.loc[df_car['doors'] == '5more', 'doors'] = '5'\\n    # df_car[\\\"doors\\\"] = pd.to_numeric(df_car[\\\"doors\\\"])\\n    # replace more in passengers to 5\\n    return df_car\\n\\n\\n\\\"\\\"\\\"\\nhttps://archive.ics.uci.edu/ml/datasets/mushroom\\n1-22 -> data\\n0 -> labels\\n\\\"\\\"\\\"\\n\\n\\ndef load_mushroom():\\n    df_mushroom = pd.read_csv(\\n        \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\\\",\\n        header=None,\\n        names=cols_mushroom,\\n    )\\n    # index mappings\\n    # X = df_mushroom.loc[:, 1:].values\\n    # y = df_mushroom.loc[:, 0].values\\n    return df_mushroom\\n\\n\\n\\\"\\\"\\\"\\nhttps://archive.ics.uci.edu/ml/datasets/Audiology+%28Standardized%29\\n0:length-2 -> data\\nlength-1 unique id (p1-p200)\\nlength -> labels\\n\\\"\\\"\\\"\\n\\n\\ndef load_audiology():\\n    df_audiology = pd.read_csv(\\n        \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/audiology/audiology.standardized.data\\\",\\n        header=None,\\n        names=cols_audiology,\\n    )\\n    # index mapping\\n    # length = len(df_audiology.columns)\\n    # X = df_audiology.loc[:, : length - 3].values\\n    # y = df_audiology.loc[:, length - 1].values\\n    df_audiology = df_audiology.drop(\\\"p-index\\\", axis=1)\\n    labels_col = df_audiology.pop(\\\"labels\\\")\\n    df_audiology.insert(0, \\\"labels\\\", labels_col)\\n    return df_audiology\\n\\n\\n\\\"\\\"\\\"\\nhttps://www.alldatascience.com/classification/wine-dataset-analysis-with-python/\\n1:length -> data\\n0 -> labels\\n\\\"\\\"\\\"\\n\\n\\ndef load_wine():\\n    df_wine = pd.read_csv(\\n        \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\\",\\n        header=None,\\n        names=cols_wine,\\n    )\\n    # index mappings\\n    # length = len(df_wine.columns)\\n    # X = df_wine.loc[:, 1:].values\\n    # y = df_wine.loc[:, 0].values\\n    return df_wine\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# utility functions\n",
    "\n",
    "cols_mushroom = [\n",
    "    \"labels\",\n",
    "    \"cap-shape\",\n",
    "    \"cap-surface\",\n",
    "    \"cap-color\",\n",
    "    \"bruises\",\n",
    "    \"odor\",\n",
    "    \"gill-attachment\",\n",
    "    \"gill-spacing\",\n",
    "    \"gill-size\",\n",
    "    \"gill-color\",\n",
    "    \"stalk-shape\",\n",
    "    \"stalk-root\",\n",
    "    \"stalk-surface-above-ring\",\n",
    "    \"stalk-surface-below-ring\",\n",
    "    \"stalk-color-above-ring\",\n",
    "    \"stalk-color-below-ring\",\n",
    "    \"veil-type\",\n",
    "    \"veil-color\",\n",
    "    \"ring-number\",\n",
    "    \"ring-type\",\n",
    "    \"spore-print-color\",\n",
    "    \"population\",\n",
    "    \"habitat\",\n",
    "]\n",
    "\n",
    "cols_car = [\"buying\", \"maintenance\", \"doors\", \"passengers\", \"boot\", \"safety\", \"labels\"]\n",
    "\n",
    "cols_audiology = [\n",
    "    \"age_gt_60\",\n",
    "    \"air\",\n",
    "    \"airBoneGap\",\n",
    "    \"ar_c\",\n",
    "    \"ar_u\",\n",
    "    \"bone\",\n",
    "    \"boneAbnormal\",\n",
    "    \"bser\",\n",
    "    \"history_buzzing\",\n",
    "    \"history_dizziness\",\n",
    "    \"history_fluctuating\",\n",
    "    \"history_fullness\",\n",
    "    \"history_heredity\",\n",
    "    \"history_nausea\",\n",
    "    \"history_noise\",\n",
    "    \"history_recruitment\",\n",
    "    \"history_ringing\",\n",
    "    \"history_roaring\",\n",
    "    \"history_vomiting\",\n",
    "    \"late_wave_poor\",\n",
    "    \"m_at_2k\",\n",
    "    \"m_cond_lt_1k\",\n",
    "    \"m_gt_1k\",\n",
    "    \"m_m_gt_2k\",\n",
    "    \"m_m_sn\",\n",
    "    \"m_m_sn_gt_1k\",\n",
    "    \"m_m_sn_gt_2k\",\n",
    "    \"m_m_sn_gt_500\",\n",
    "    \"m_p_sn_gt_2k\",\n",
    "    \"m_s_gt_500\",\n",
    "    \"m_s_sn\",\n",
    "    \"m_s_sn_gt_1k\",\n",
    "    \"m_s_sn_gt_2k\",\n",
    "    \"m_s_sn_gt_3k\",\n",
    "    \"m_s_sn_gt_4k\",\n",
    "    \"m_sn_2_3k\",\n",
    "    \"m_sn_gt_1k\",\n",
    "    \"m_sn_gt_2k\",\n",
    "    \"m_sn_gt_3k\",\n",
    "    \"m_sn_gt_4k\",\n",
    "    \"m_sn_gt_500\",\n",
    "    \"m_sn_gt_6k\",\n",
    "    \"m_sn_lt_1k\",\n",
    "    \"m_sn_lt_2k\",\n",
    "    \"m_sn_lt_3k\",\n",
    "    \"middle_wave_poor\",\n",
    "    \"mod_gt_4k\",\n",
    "    \"mod_mixed\",\n",
    "    \"vmod_s_mixed\",\n",
    "    \"mod_s_sn_gt_500\",\n",
    "    \"mod_sn\",\n",
    "    \"mod_sn_gt_1k\",\n",
    "    \"mod_sn_gt_2k\",\n",
    "    \"mod_sn_gt_3k\",\n",
    "    \"mod_sn_gt_4k\",\n",
    "    \"mod_sn_gt_500\",\n",
    "    \"notch_4k\",\n",
    "    \"notch_at_4k\",\n",
    "    \"o_ar_c\",\n",
    "    \"o_ar_u\",\n",
    "    \"s_sn_gt_1k\",\n",
    "    \"s_sn_gt_2k\",\n",
    "    \"s_sn_gt_4k\",\n",
    "    \"speech\",\n",
    "    \"static_normal\",\n",
    "    \"tymp\",\n",
    "    \"viith_nerve_signs\",\n",
    "    \"wave_V_delayed\",\n",
    "    \"waveform_ItoV_prolonged\",\n",
    "    \"p-index\",\n",
    "    \"labels\",\n",
    "]\n",
    "\n",
    "cols_wine = [\n",
    "    \"labels\",\n",
    "    \"alcohol\",\n",
    "    \"mallic-acid\",\n",
    "    \"alcalinity\",\n",
    "    \"ash\",\n",
    "    \"magnesium\",\n",
    "    \"total-phenols\",\n",
    "    \"flavonids\",\n",
    "    \"nonflavonid-phenols\",\n",
    "    \"proanthocyanins\",\n",
    "    \"color-intensity\",\n",
    "    \"hue\",\n",
    "    \"od-of-diluted-wines\",\n",
    "    \"proline\",\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "https://archive.ics.uci.edu/ml/datasets/car+evaluation\n",
    "0-5 -> data\n",
    "6 -> labels\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_car():\n",
    "    df_car = pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\",\n",
    "        header=None,\n",
    "        names=cols_car,\n",
    "    )\n",
    "    # mappings using indexes:\n",
    "    # X = df_car.loc[:, :5].values\n",
    "    # y = df_car.loc[:, 6].values\n",
    "    labels_col = df_car.pop(\"labels\")\n",
    "    df_car.insert(0, \"labels\", labels_col)\n",
    "    # replace 5more in doors to 5\n",
    "    # df_car.loc[df_car['doors'] == '5more', 'doors'] = '5'\n",
    "    # df_car[\"doors\"] = pd.to_numeric(df_car[\"doors\"])\n",
    "    # replace more in passengers to 5\n",
    "    return df_car\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "https://archive.ics.uci.edu/ml/datasets/mushroom\n",
    "1-22 -> data\n",
    "0 -> labels\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_mushroom():\n",
    "    df_mushroom = pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\",\n",
    "        header=None,\n",
    "        names=cols_mushroom,\n",
    "    )\n",
    "    # index mappings\n",
    "    # X = df_mushroom.loc[:, 1:].values\n",
    "    # y = df_mushroom.loc[:, 0].values\n",
    "    return df_mushroom\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "https://archive.ics.uci.edu/ml/datasets/Audiology+%28Standardized%29\n",
    "0:length-2 -> data\n",
    "length-1 unique id (p1-p200)\n",
    "length -> labels\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_audiology():\n",
    "    df_audiology = pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/audiology/audiology.standardized.data\",\n",
    "        header=None,\n",
    "        names=cols_audiology,\n",
    "    )\n",
    "    # index mapping\n",
    "    # length = len(df_audiology.columns)\n",
    "    # X = df_audiology.loc[:, : length - 3].values\n",
    "    # y = df_audiology.loc[:, length - 1].values\n",
    "    df_audiology = df_audiology.drop(\"p-index\", axis=1)\n",
    "    labels_col = df_audiology.pop(\"labels\")\n",
    "    df_audiology.insert(0, \"labels\", labels_col)\n",
    "    return df_audiology\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "https://www.alldatascience.com/classification/wine-dataset-analysis-with-python/\n",
    "1:length -> data\n",
    "0 -> labels\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_wine():\n",
    "    df_wine = pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\",\n",
    "        header=None,\n",
    "        names=cols_wine,\n",
    "    )\n",
    "    # index mappings\n",
    "    # length = len(df_wine.columns)\n",
    "    # X = df_wine.loc[:, 1:].values\n",
    "    # y = df_wine.loc[:, 0].values\n",
    "    return df_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e3ea44b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   labels                    8124 non-null   object\n",
      " 1   cap-shape                 8124 non-null   object\n",
      " 2   cap-surface               8124 non-null   object\n",
      " 3   cap-color                 8124 non-null   object\n",
      " 4   bruises                   8124 non-null   object\n",
      " 5   odor                      8124 non-null   object\n",
      " 6   gill-attachment           8124 non-null   object\n",
      " 7   gill-spacing              8124 non-null   object\n",
      " 8   gill-size                 8124 non-null   object\n",
      " 9   gill-color                8124 non-null   object\n",
      " 10  stalk-shape               8124 non-null   object\n",
      " 11  stalk-root                8124 non-null   object\n",
      " 12  stalk-surface-above-ring  8124 non-null   object\n",
      " 13  stalk-surface-below-ring  8124 non-null   object\n",
      " 14  stalk-color-above-ring    8124 non-null   object\n",
      " 15  stalk-color-below-ring    8124 non-null   object\n",
      " 16  veil-type                 8124 non-null   object\n",
      " 17  veil-color                8124 non-null   object\n",
      " 18  ring-number               8124 non-null   object\n",
      " 19  ring-type                 8124 non-null   object\n",
      " 20  spore-print-color         8124 non-null   object\n",
      " 21  population                8124 non-null   object\n",
      " 22  habitat                   8124 non-null   object\n",
      "dtypes: object(23)\n",
      "memory usage: 1.4+ MB\n",
      "None\n",
      "Size of X:  (8124, 22)\n",
      "Size of y:  (8124,)\n",
      "Size of dataset costs:  (1, 22)\n",
      "Cost of classification on full dataset:  137593\n",
      "Data has been split.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"# Choose dataset\\n# dataset = load_car()\\ndataset = load_mushroom()\\n# dataset = load_audiology()\\n### dataset = load_wine() # all cols numerical, doesn't work\\n\\nprint(dataset.info())\\n# print(\\\"First five records:\\\")\\n# print(dataset.head())\\n\\n# Extract to X and y\\nX_cat = dataset.loc[:, dataset.columns != \\\"labels\\\"]\\ny_cat = dataset.loc[:, \\\"labels\\\"]\\n\\nprint(\\\"Size of X: \\\", np.shape(X_cat))\\nprint(\\\"Size of y: \\\", np.shape(y_cat))\\n\\n# Generate a matrix of costs\\nmax_cost_allowed = 10000\\n\\ndataset_costs = pd.DataFrame(\\n    np.random.randint(0, max_cost_allowed, size=(1, np.shape(X_cat)[1])),\\n    columns=X_cat.columns,\\n)\\n\\nprint(\\\"Size of dataset costs: \\\", np.shape(dataset_costs))\\nprint(\\\"Cost of classification on full dataset: \\\", dataset_costs.sum(axis=1)[0])\\n\\nmax_seed_val = 2 ** 32 - 1\\n\\n# Split dataset into training set and test set\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X_cat, y_cat, test_size=0.2, random_state=random.randrange(0, max_seed_val),\\n)\\nprint(\\\"Data has been split.\\\")\\n#print(\\\"X contains features: \\\", X_train.columns == \\\"index\\\")\";\n",
       "                var nbb_formatted_code = \"# Choose dataset\\n# dataset = load_car()\\ndataset = load_mushroom()\\n# dataset = load_audiology()\\n### dataset = load_wine() # all cols numerical, doesn't work\\n\\nprint(dataset.info())\\n# print(\\\"First five records:\\\")\\n# print(dataset.head())\\n\\n# Extract to X and y\\nX_cat = dataset.loc[:, dataset.columns != \\\"labels\\\"]\\ny_cat = dataset.loc[:, \\\"labels\\\"]\\n\\nprint(\\\"Size of X: \\\", np.shape(X_cat))\\nprint(\\\"Size of y: \\\", np.shape(y_cat))\\n\\n# Generate a matrix of costs\\nmax_cost_allowed = 10000\\n\\ndataset_costs = pd.DataFrame(\\n    np.random.randint(0, max_cost_allowed, size=(1, np.shape(X_cat)[1])),\\n    columns=X_cat.columns,\\n)\\n\\nprint(\\\"Size of dataset costs: \\\", np.shape(dataset_costs))\\nprint(\\\"Cost of classification on full dataset: \\\", dataset_costs.sum(axis=1)[0])\\n\\nmax_seed_val = 2 ** 32 - 1\\n\\n# Split dataset into training set and test set\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X_cat, y_cat, test_size=0.2, random_state=random.randrange(0, max_seed_val),\\n)\\nprint(\\\"Data has been split.\\\")\\n# print(\\\"X contains features: \\\", X_train.columns == \\\"index\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose dataset\n",
    "# dataset = load_car()\n",
    "dataset = load_mushroom()\n",
    "# dataset = load_audiology()\n",
    "### dataset = load_wine() # all cols numerical, doesn't work\n",
    "\n",
    "print(dataset.info())\n",
    "# print(\"First five records:\")\n",
    "# print(dataset.head())\n",
    "\n",
    "# Extract to X and y\n",
    "X_cat = dataset.loc[:, dataset.columns != \"labels\"]\n",
    "y_cat = dataset.loc[:, \"labels\"]\n",
    "\n",
    "print(\"Size of X: \", np.shape(X_cat))\n",
    "print(\"Size of y: \", np.shape(y_cat))\n",
    "\n",
    "# Generate a matrix of costs\n",
    "max_cost_allowed = 10000\n",
    "\n",
    "dataset_costs = pd.DataFrame(\n",
    "    np.random.randint(0, max_cost_allowed, size=(1, np.shape(X_cat)[1])),\n",
    "    columns=X_cat.columns,\n",
    ")\n",
    "\n",
    "print(\"Size of dataset costs: \", np.shape(dataset_costs))\n",
    "print(\"Cost of classification on full dataset: \", dataset_costs.sum(axis=1)[0])\n",
    "\n",
    "max_seed_val = 2 ** 32 - 1\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_cat, y_cat, test_size=0.2, random_state=random.randrange(0, max_seed_val),\n",
    ")\n",
    "print(\"Data has been split.\")\n",
    "# print(\"X contains features: \", X_train.columns == \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba83093b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# Collectors of values\\n\\ncols_one_hot = [\\n    \\\"cap-shape\\\",\\n    \\\"cap-surface\\\",\\n    \\\"cap-color\\\",\\n    \\\"bruises\\\",\\n    \\\"odor\\\",\\n    \\\"gill-attachment\\\",\\n    \\\"gill-spacing\\\",\\n    \\\"gill-size\\\",\\n    \\\"gill-color\\\",\\n    \\\"stalk-shape\\\",\\n    \\\"stalk-root\\\",\\n    \\\"stalk-surface-above-ring\\\",\\n    \\\"stalk-surface-below-ring\\\",\\n    \\\"stalk-color-above-ring\\\",\\n    \\\"stalk-color-below-ring\\\",\\n    \\\"veil-type\\\",\\n    \\\"veil-color\\\",\\n    \\\"ring-number\\\",\\n    \\\"ring-type\\\",\\n    \\\"spore-print-color\\\",\\n    \\\"habitat\\\",\\n    \\\"age_gt_60\\\",\\n    \\\"airBoneGap\\\",\\n    \\\"boneAbnormal\\\",\\n    \\\"history_buzzing\\\",\\n    \\\"history_dizziness\\\",\\n    \\\"history_fluctuating\\\",\\n    \\\"history_fullness\\\",\\n    \\\"history_heredity\\\",\\n    \\\"history_nausea\\\",\\n    \\\"history_noise\\\",\\n    \\\"history_recruitment\\\",\\n    \\\"history_ringing\\\",\\n    \\\"history_roaring\\\",\\n    \\\"history_vomiting\\\",\\n    \\\"late_wave_poor\\\",\\n    \\\"m_at_2k\\\",\\n    \\\"m_cond_lt_1k\\\",\\n    \\\"m_gt_1k\\\",\\n    \\\"m_m_gt_2k\\\",\\n    \\\"m_m_sn\\\",\\n    \\\"m_m_sn_gt_1k\\\",\\n    \\\"m_m_sn_gt_2k\\\",\\n    \\\"m_m_sn_gt_500\\\",\\n    \\\"m_p_sn_gt_2k\\\",\\n    \\\"m_s_gt_500\\\",\\n    \\\"m_s_sn\\\",\\n    \\\"m_s_sn_gt_1k\\\",\\n    \\\"m_s_sn_gt_2k\\\",\\n    \\\"m_s_sn_gt_3k\\\",\\n    \\\"m_s_sn_gt_4k\\\",\\n    \\\"m_sn_2_3k\\\",\\n    \\\"m_sn_gt_1k\\\",\\n    \\\"m_sn_gt_2k\\\",\\n    \\\"m_sn_gt_3k\\\",\\n    \\\"m_sn_gt_4k\\\",\\n    \\\"m_sn_gt_500\\\",\\n    \\\"m_sn_gt_6k\\\",\\n    \\\"m_sn_lt_1k\\\",\\n    \\\"m_sn_lt_2k\\\",\\n    \\\"m_sn_lt_3k\\\",\\n    \\\"middle_wave_poor\\\",\\n    \\\"mod_gt_4k\\\",\\n    \\\"mod_mixed\\\",\\n    \\\"vmod_s_mixed\\\",\\n    \\\"mod_s_sn_gt_500\\\",\\n    \\\"mod_sn\\\",\\n    \\\"mod_sn_gt_1k\\\",\\n    \\\"mod_sn_gt_2k\\\",\\n    \\\"mod_sn_gt_3k\\\",\\n    \\\"mod_sn_gt_4k\\\",\\n    \\\"mod_sn_gt_500\\\",\\n    \\\"notch_4k\\\",\\n    \\\"notch_at_4k\\\",\\n    \\\"s_sn_gt_1k\\\",\\n    \\\"s_sn_gt_2k\\\",\\n    \\\"s_sn_gt_4k\\\",\\n    \\\"static_normal\\\",\\n    \\\"viith_nerve_signs\\\",\\n    \\\"wave_V_delayed\\\",\\n    \\\"waveform_ItoV_prolonged\\\",\\n]\\n\\ncols_ordinal = [\\n    \\\"buying\\\",\\n    \\\"maintenance\\\",\\n    \\\"doors\\\",\\n    \\\"passengers\\\",\\n    \\\"boot\\\",\\n    \\\"safety\\\",\\n    \\\"population\\\",\\n    \\\"air\\\",\\n    \\\"ar_c\\\",\\n    \\\"ar_u\\\",\\n    \\\"bser\\\",\\n    \\\"bone\\\",\\n    \\\"o_ar_c\\\",\\n    \\\"o_ar_u\\\",\\n    \\\"speech\\\",\\n    \\\"tymp\\\",\\n]\\n\\n\\ndef intersection(lst1, lst2):\\n    return [value for value in lst1 if value in lst2]\\n\\n\\ndef collect_current_one_hot_columns(argNames):\\n    # make list of all values and create steps for them\\n    return intersection(cols_one_hot, argNames)\\n\\n\\ndef collect_current_ordinal_columns(argNames):\\n    # make list of all values and create steps for them\\n    return intersection(cols_ordinal, argNames)\";\n",
       "                var nbb_formatted_code = \"# Collectors of values\\n\\ncols_one_hot = [\\n    \\\"cap-shape\\\",\\n    \\\"cap-surface\\\",\\n    \\\"cap-color\\\",\\n    \\\"bruises\\\",\\n    \\\"odor\\\",\\n    \\\"gill-attachment\\\",\\n    \\\"gill-spacing\\\",\\n    \\\"gill-size\\\",\\n    \\\"gill-color\\\",\\n    \\\"stalk-shape\\\",\\n    \\\"stalk-root\\\",\\n    \\\"stalk-surface-above-ring\\\",\\n    \\\"stalk-surface-below-ring\\\",\\n    \\\"stalk-color-above-ring\\\",\\n    \\\"stalk-color-below-ring\\\",\\n    \\\"veil-type\\\",\\n    \\\"veil-color\\\",\\n    \\\"ring-number\\\",\\n    \\\"ring-type\\\",\\n    \\\"spore-print-color\\\",\\n    \\\"habitat\\\",\\n    \\\"age_gt_60\\\",\\n    \\\"airBoneGap\\\",\\n    \\\"boneAbnormal\\\",\\n    \\\"history_buzzing\\\",\\n    \\\"history_dizziness\\\",\\n    \\\"history_fluctuating\\\",\\n    \\\"history_fullness\\\",\\n    \\\"history_heredity\\\",\\n    \\\"history_nausea\\\",\\n    \\\"history_noise\\\",\\n    \\\"history_recruitment\\\",\\n    \\\"history_ringing\\\",\\n    \\\"history_roaring\\\",\\n    \\\"history_vomiting\\\",\\n    \\\"late_wave_poor\\\",\\n    \\\"m_at_2k\\\",\\n    \\\"m_cond_lt_1k\\\",\\n    \\\"m_gt_1k\\\",\\n    \\\"m_m_gt_2k\\\",\\n    \\\"m_m_sn\\\",\\n    \\\"m_m_sn_gt_1k\\\",\\n    \\\"m_m_sn_gt_2k\\\",\\n    \\\"m_m_sn_gt_500\\\",\\n    \\\"m_p_sn_gt_2k\\\",\\n    \\\"m_s_gt_500\\\",\\n    \\\"m_s_sn\\\",\\n    \\\"m_s_sn_gt_1k\\\",\\n    \\\"m_s_sn_gt_2k\\\",\\n    \\\"m_s_sn_gt_3k\\\",\\n    \\\"m_s_sn_gt_4k\\\",\\n    \\\"m_sn_2_3k\\\",\\n    \\\"m_sn_gt_1k\\\",\\n    \\\"m_sn_gt_2k\\\",\\n    \\\"m_sn_gt_3k\\\",\\n    \\\"m_sn_gt_4k\\\",\\n    \\\"m_sn_gt_500\\\",\\n    \\\"m_sn_gt_6k\\\",\\n    \\\"m_sn_lt_1k\\\",\\n    \\\"m_sn_lt_2k\\\",\\n    \\\"m_sn_lt_3k\\\",\\n    \\\"middle_wave_poor\\\",\\n    \\\"mod_gt_4k\\\",\\n    \\\"mod_mixed\\\",\\n    \\\"vmod_s_mixed\\\",\\n    \\\"mod_s_sn_gt_500\\\",\\n    \\\"mod_sn\\\",\\n    \\\"mod_sn_gt_1k\\\",\\n    \\\"mod_sn_gt_2k\\\",\\n    \\\"mod_sn_gt_3k\\\",\\n    \\\"mod_sn_gt_4k\\\",\\n    \\\"mod_sn_gt_500\\\",\\n    \\\"notch_4k\\\",\\n    \\\"notch_at_4k\\\",\\n    \\\"s_sn_gt_1k\\\",\\n    \\\"s_sn_gt_2k\\\",\\n    \\\"s_sn_gt_4k\\\",\\n    \\\"static_normal\\\",\\n    \\\"viith_nerve_signs\\\",\\n    \\\"wave_V_delayed\\\",\\n    \\\"waveform_ItoV_prolonged\\\",\\n]\\n\\ncols_ordinal = [\\n    \\\"buying\\\",\\n    \\\"maintenance\\\",\\n    \\\"doors\\\",\\n    \\\"passengers\\\",\\n    \\\"boot\\\",\\n    \\\"safety\\\",\\n    \\\"population\\\",\\n    \\\"air\\\",\\n    \\\"ar_c\\\",\\n    \\\"ar_u\\\",\\n    \\\"bser\\\",\\n    \\\"bone\\\",\\n    \\\"o_ar_c\\\",\\n    \\\"o_ar_u\\\",\\n    \\\"speech\\\",\\n    \\\"tymp\\\",\\n]\\n\\n\\ndef intersection(lst1, lst2):\\n    return [value for value in lst1 if value in lst2]\\n\\n\\ndef collect_current_one_hot_columns(argNames):\\n    # make list of all values and create steps for them\\n    return intersection(cols_one_hot, argNames)\\n\\n\\ndef collect_current_ordinal_columns(argNames):\\n    # make list of all values and create steps for them\\n    return intersection(cols_ordinal, argNames)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Collectors of values\n",
    "\n",
    "cols_one_hot = [\n",
    "    \"cap-shape\",\n",
    "    \"cap-surface\",\n",
    "    \"cap-color\",\n",
    "    \"bruises\",\n",
    "    \"odor\",\n",
    "    \"gill-attachment\",\n",
    "    \"gill-spacing\",\n",
    "    \"gill-size\",\n",
    "    \"gill-color\",\n",
    "    \"stalk-shape\",\n",
    "    \"stalk-root\",\n",
    "    \"stalk-surface-above-ring\",\n",
    "    \"stalk-surface-below-ring\",\n",
    "    \"stalk-color-above-ring\",\n",
    "    \"stalk-color-below-ring\",\n",
    "    \"veil-type\",\n",
    "    \"veil-color\",\n",
    "    \"ring-number\",\n",
    "    \"ring-type\",\n",
    "    \"spore-print-color\",\n",
    "    \"habitat\",\n",
    "    \"age_gt_60\",\n",
    "    \"airBoneGap\",\n",
    "    \"boneAbnormal\",\n",
    "    \"history_buzzing\",\n",
    "    \"history_dizziness\",\n",
    "    \"history_fluctuating\",\n",
    "    \"history_fullness\",\n",
    "    \"history_heredity\",\n",
    "    \"history_nausea\",\n",
    "    \"history_noise\",\n",
    "    \"history_recruitment\",\n",
    "    \"history_ringing\",\n",
    "    \"history_roaring\",\n",
    "    \"history_vomiting\",\n",
    "    \"late_wave_poor\",\n",
    "    \"m_at_2k\",\n",
    "    \"m_cond_lt_1k\",\n",
    "    \"m_gt_1k\",\n",
    "    \"m_m_gt_2k\",\n",
    "    \"m_m_sn\",\n",
    "    \"m_m_sn_gt_1k\",\n",
    "    \"m_m_sn_gt_2k\",\n",
    "    \"m_m_sn_gt_500\",\n",
    "    \"m_p_sn_gt_2k\",\n",
    "    \"m_s_gt_500\",\n",
    "    \"m_s_sn\",\n",
    "    \"m_s_sn_gt_1k\",\n",
    "    \"m_s_sn_gt_2k\",\n",
    "    \"m_s_sn_gt_3k\",\n",
    "    \"m_s_sn_gt_4k\",\n",
    "    \"m_sn_2_3k\",\n",
    "    \"m_sn_gt_1k\",\n",
    "    \"m_sn_gt_2k\",\n",
    "    \"m_sn_gt_3k\",\n",
    "    \"m_sn_gt_4k\",\n",
    "    \"m_sn_gt_500\",\n",
    "    \"m_sn_gt_6k\",\n",
    "    \"m_sn_lt_1k\",\n",
    "    \"m_sn_lt_2k\",\n",
    "    \"m_sn_lt_3k\",\n",
    "    \"middle_wave_poor\",\n",
    "    \"mod_gt_4k\",\n",
    "    \"mod_mixed\",\n",
    "    \"vmod_s_mixed\",\n",
    "    \"mod_s_sn_gt_500\",\n",
    "    \"mod_sn\",\n",
    "    \"mod_sn_gt_1k\",\n",
    "    \"mod_sn_gt_2k\",\n",
    "    \"mod_sn_gt_3k\",\n",
    "    \"mod_sn_gt_4k\",\n",
    "    \"mod_sn_gt_500\",\n",
    "    \"notch_4k\",\n",
    "    \"notch_at_4k\",\n",
    "    \"s_sn_gt_1k\",\n",
    "    \"s_sn_gt_2k\",\n",
    "    \"s_sn_gt_4k\",\n",
    "    \"static_normal\",\n",
    "    \"viith_nerve_signs\",\n",
    "    \"wave_V_delayed\",\n",
    "    \"waveform_ItoV_prolonged\",\n",
    "]\n",
    "\n",
    "cols_ordinal = [\n",
    "    \"buying\",\n",
    "    \"maintenance\",\n",
    "    \"doors\",\n",
    "    \"passengers\",\n",
    "    \"boot\",\n",
    "    \"safety\",\n",
    "    \"population\",\n",
    "    \"air\",\n",
    "    \"ar_c\",\n",
    "    \"ar_u\",\n",
    "    \"bser\",\n",
    "    \"bone\",\n",
    "    \"o_ar_c\",\n",
    "    \"o_ar_u\",\n",
    "    \"speech\",\n",
    "    \"tymp\",\n",
    "]\n",
    "\n",
    "\n",
    "def intersection(lst1, lst2):\n",
    "    return [value for value in lst1 if value in lst2]\n",
    "\n",
    "\n",
    "def collect_current_one_hot_columns(argNames):\n",
    "    # make list of all values and create steps for them\n",
    "    return intersection(cols_one_hot, argNames)\n",
    "\n",
    "\n",
    "def collect_current_ordinal_columns(argNames):\n",
    "    # make list of all values and create steps for them\n",
    "    return intersection(cols_ordinal, argNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff6bfe05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order created.\n",
      "    buying maintenance    doors passengers     boot   safety population  \\\n",
      "0      low         low        2          2    small      low          y   \n",
      "1      med         med        3          4      med      med          v   \n",
      "2     high        high        4       more      big     high          s   \n",
      "3    vhigh       vhigh    5more    filler1  filler1  filler1          n   \n",
      "4  filler1     filler1  filler1    filler2  filler2  filler2          c   \n",
      "5  filler2     filler2  filler2    filler3  filler3  filler3          a   \n",
      "6  filler3     filler3  filler3    filler4  filler4  filler4    filler1   \n",
      "\n",
      "        air      ar_c      ar_u      bser        bone    o_ar_c    o_ar_u  \\\n",
      "0    normal         ?         ?         ?           ?         ?         ?   \n",
      "1      mild    absent    absent    normal  unmeasured    absent    absent   \n",
      "2  moderate    normal    normal  degraded      normal    normal    normal   \n",
      "3    severe  elevated  elevated   filler1        mild  elevated  elevated   \n",
      "4  profound   filler1   filler1   filler2    moderate   filler1   filler1   \n",
      "5   filler1   filler2   filler2   filler3     filler1   filler2   filler2   \n",
      "6   filler2   filler3   filler3   filler4     filler3   filler3   filler3   \n",
      "\n",
      "       speech     tymp  \n",
      "0           ?        a  \n",
      "1  unmeasured       as  \n",
      "2   very_poor        b  \n",
      "3        poor       ad  \n",
      "4      normal        c  \n",
      "5        good  filler1  \n",
      "6   very_good  filler2  \n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# Make order of categories per each column in ordinal_columns\\norder_of_ordinal_categories = pd.DataFrame.from_dict(\\n    {\\n        \\\"buying\\\": [\\\"low\\\", \\\"med\\\", \\\"high\\\", \\\"vhigh\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"maintenance\\\": [\\\"low\\\", \\\"med\\\", \\\"high\\\", \\\"vhigh\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"doors\\\": [\\\"2\\\", \\\"3\\\", \\\"4\\\", \\\"5more\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"passengers\\\": [\\\"2\\\", \\\"4\\\", \\\"more\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\", \\\"filler4\\\"],\\n        \\\"boot\\\": [\\\"small\\\", \\\"med\\\", \\\"big\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\", \\\"filler4\\\"],\\n        \\\"safety\\\": [\\\"low\\\", \\\"med\\\", \\\"high\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\", \\\"filler4\\\"],\\n        \\\"population\\\": [\\\"y\\\", \\\"v\\\", \\\"s\\\", \\\"n\\\", \\\"c\\\", \\\"a\\\", \\\"filler1\\\"],\\n        \\\"air\\\": [\\n            \\\"normal\\\",\\n            \\\"mild\\\",\\n            \\\"moderate\\\",\\n            \\\"severe\\\",\\n            \\\"profound\\\",\\n            \\\"filler1\\\",\\n            \\\"filler2\\\",\\n        ],\\n        \\\"ar_c\\\": [\\\"?\\\", \\\"absent\\\", \\\"normal\\\", \\\"elevated\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"ar_u\\\": [\\\"?\\\", \\\"absent\\\", \\\"normal\\\", \\\"elevated\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"bser\\\": [\\\"?\\\", \\\"normal\\\", \\\"degraded\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\", \\\"filler4\\\"],\\n        \\\"bone\\\": [\\\"?\\\", \\\"unmeasured\\\", \\\"normal\\\", \\\"mild\\\", \\\"moderate\\\", \\\"filler1\\\", \\\"filler3\\\"],\\n        \\\"o_ar_c\\\": [\\n            \\\"?\\\",\\n            \\\"absent\\\",\\n            \\\"normal\\\",\\n            \\\"elevated\\\",\\n            \\\"filler1\\\",\\n            \\\"filler2\\\",\\n            \\\"filler3\\\",\\n        ],\\n        \\\"o_ar_u\\\": [\\n            \\\"?\\\",\\n            \\\"absent\\\",\\n            \\\"normal\\\",\\n            \\\"elevated\\\",\\n            \\\"filler1\\\",\\n            \\\"filler2\\\",\\n            \\\"filler3\\\",\\n        ],\\n        \\\"speech\\\": [\\n            \\\"?\\\",\\n            \\\"unmeasured\\\",\\n            \\\"very_poor\\\",\\n            \\\"poor\\\",\\n            \\\"normal\\\",\\n            \\\"good\\\",\\n            \\\"very_good\\\",\\n        ],\\n        \\\"tymp\\\": [\\\"a\\\", \\\"as\\\", \\\"b\\\", \\\"ad\\\", \\\"c\\\", \\\"filler1\\\", \\\"filler2\\\"],\\n    }\\n)\\n\\nprint(\\\"Order created.\\\")\\nprint(order_of_ordinal_categories)\";\n",
       "                var nbb_formatted_code = \"# Make order of categories per each column in ordinal_columns\\norder_of_ordinal_categories = pd.DataFrame.from_dict(\\n    {\\n        \\\"buying\\\": [\\\"low\\\", \\\"med\\\", \\\"high\\\", \\\"vhigh\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"maintenance\\\": [\\\"low\\\", \\\"med\\\", \\\"high\\\", \\\"vhigh\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"doors\\\": [\\\"2\\\", \\\"3\\\", \\\"4\\\", \\\"5more\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"passengers\\\": [\\\"2\\\", \\\"4\\\", \\\"more\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\", \\\"filler4\\\"],\\n        \\\"boot\\\": [\\\"small\\\", \\\"med\\\", \\\"big\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\", \\\"filler4\\\"],\\n        \\\"safety\\\": [\\\"low\\\", \\\"med\\\", \\\"high\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\", \\\"filler4\\\"],\\n        \\\"population\\\": [\\\"y\\\", \\\"v\\\", \\\"s\\\", \\\"n\\\", \\\"c\\\", \\\"a\\\", \\\"filler1\\\"],\\n        \\\"air\\\": [\\n            \\\"normal\\\",\\n            \\\"mild\\\",\\n            \\\"moderate\\\",\\n            \\\"severe\\\",\\n            \\\"profound\\\",\\n            \\\"filler1\\\",\\n            \\\"filler2\\\",\\n        ],\\n        \\\"ar_c\\\": [\\\"?\\\", \\\"absent\\\", \\\"normal\\\", \\\"elevated\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"ar_u\\\": [\\\"?\\\", \\\"absent\\\", \\\"normal\\\", \\\"elevated\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\"],\\n        \\\"bser\\\": [\\\"?\\\", \\\"normal\\\", \\\"degraded\\\", \\\"filler1\\\", \\\"filler2\\\", \\\"filler3\\\", \\\"filler4\\\"],\\n        \\\"bone\\\": [\\\"?\\\", \\\"unmeasured\\\", \\\"normal\\\", \\\"mild\\\", \\\"moderate\\\", \\\"filler1\\\", \\\"filler3\\\"],\\n        \\\"o_ar_c\\\": [\\n            \\\"?\\\",\\n            \\\"absent\\\",\\n            \\\"normal\\\",\\n            \\\"elevated\\\",\\n            \\\"filler1\\\",\\n            \\\"filler2\\\",\\n            \\\"filler3\\\",\\n        ],\\n        \\\"o_ar_u\\\": [\\n            \\\"?\\\",\\n            \\\"absent\\\",\\n            \\\"normal\\\",\\n            \\\"elevated\\\",\\n            \\\"filler1\\\",\\n            \\\"filler2\\\",\\n            \\\"filler3\\\",\\n        ],\\n        \\\"speech\\\": [\\n            \\\"?\\\",\\n            \\\"unmeasured\\\",\\n            \\\"very_poor\\\",\\n            \\\"poor\\\",\\n            \\\"normal\\\",\\n            \\\"good\\\",\\n            \\\"very_good\\\",\\n        ],\\n        \\\"tymp\\\": [\\\"a\\\", \\\"as\\\", \\\"b\\\", \\\"ad\\\", \\\"c\\\", \\\"filler1\\\", \\\"filler2\\\"],\\n    }\\n)\\n\\nprint(\\\"Order created.\\\")\\nprint(order_of_ordinal_categories)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make order of categories per each column in ordinal_columns\n",
    "order_of_ordinal_categories = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"buying\": [\"low\", \"med\", \"high\", \"vhigh\", \"filler1\", \"filler2\", \"filler3\"],\n",
    "        \"maintenance\": [\"low\", \"med\", \"high\", \"vhigh\", \"filler1\", \"filler2\", \"filler3\"],\n",
    "        \"doors\": [\"2\", \"3\", \"4\", \"5more\", \"filler1\", \"filler2\", \"filler3\"],\n",
    "        \"passengers\": [\"2\", \"4\", \"more\", \"filler1\", \"filler2\", \"filler3\", \"filler4\"],\n",
    "        \"boot\": [\"small\", \"med\", \"big\", \"filler1\", \"filler2\", \"filler3\", \"filler4\"],\n",
    "        \"safety\": [\"low\", \"med\", \"high\", \"filler1\", \"filler2\", \"filler3\", \"filler4\"],\n",
    "        \"population\": [\"y\", \"v\", \"s\", \"n\", \"c\", \"a\", \"filler1\"],\n",
    "        \"air\": [\n",
    "            \"normal\",\n",
    "            \"mild\",\n",
    "            \"moderate\",\n",
    "            \"severe\",\n",
    "            \"profound\",\n",
    "            \"filler1\",\n",
    "            \"filler2\",\n",
    "        ],\n",
    "        \"ar_c\": [\"?\", \"absent\", \"normal\", \"elevated\", \"filler1\", \"filler2\", \"filler3\"],\n",
    "        \"ar_u\": [\"?\", \"absent\", \"normal\", \"elevated\", \"filler1\", \"filler2\", \"filler3\"],\n",
    "        \"bser\": [\"?\", \"normal\", \"degraded\", \"filler1\", \"filler2\", \"filler3\", \"filler4\"],\n",
    "        \"bone\": [\"?\", \"unmeasured\", \"normal\", \"mild\", \"moderate\", \"filler1\", \"filler3\"],\n",
    "        \"o_ar_c\": [\n",
    "            \"?\",\n",
    "            \"absent\",\n",
    "            \"normal\",\n",
    "            \"elevated\",\n",
    "            \"filler1\",\n",
    "            \"filler2\",\n",
    "            \"filler3\",\n",
    "        ],\n",
    "        \"o_ar_u\": [\n",
    "            \"?\",\n",
    "            \"absent\",\n",
    "            \"normal\",\n",
    "            \"elevated\",\n",
    "            \"filler1\",\n",
    "            \"filler2\",\n",
    "            \"filler3\",\n",
    "        ],\n",
    "        \"speech\": [\n",
    "            \"?\",\n",
    "            \"unmeasured\",\n",
    "            \"very_poor\",\n",
    "            \"poor\",\n",
    "            \"normal\",\n",
    "            \"good\",\n",
    "            \"very_good\",\n",
    "        ],\n",
    "        \"tymp\": [\"a\", \"as\", \"b\", \"ad\", \"c\", \"filler1\", \"filler2\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Order created.\")\n",
    "print(order_of_ordinal_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1734dfe3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one hot:  ['cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'habitat']\n",
      "ordinal:  ['population']\n",
      "Successfully encoded dataset.\n",
      "X_train (6499, 112)\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 4.]\n",
      " [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 2.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]]\n",
      "(1625, 112)\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 2.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 4.]]\n",
      "Successfully encoded dataset labels.\n",
      "Train dataset contains  (6499, 112) , y dataset contains  (6499,)\n",
      "Test dataset contains  (1625, 112) , y dataset contains  (1625,)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def calculate_current_order_of_ordinal_columns_to_encode():\\n    # Get common cols to feed them in proper order to ordinal encoder\\n    index_of_common_cols = order_of_ordinal_categories.columns.intersection(\\n        current_columns_ordinal\\n    )\\n    # Convert to list\\n    order_of_ordinal_categories_list = (\\n        order_of_ordinal_categories[index_of_common_cols].values.transpose().tolist()\\n    )\\n    return order_of_ordinal_categories_list\\n\\n\\n# Get current ordinal and one hot columns\\ntotal_column_list = X_cat.select_dtypes(include=\\\"object\\\").columns\\ncurrent_columns_one_hot = collect_current_one_hot_columns(total_column_list)\\ncurrent_columns_ordinal = collect_current_ordinal_columns(total_column_list)\\n\\ncurrent_ordinal_col_ordering_to_encode = calculate_current_order_of_ordinal_columns_to_encode()\\n\\nprint(\\\"one hot: \\\", current_columns_one_hot)\\nprint(\\\"ordinal: \\\", current_columns_ordinal)\\n\\n# for debugging: unknown value in n-th column means n-th col from this is missing that value(s)\\n# print(index_of_common_cols)\\n#for col in X_train:\\n#    print(col, \\\": \\\", X_train[col].unique())\\n\\n# Create column transformer\\ncolumn_transform = make_column_transformer(\\n    (OneHotEncoder(), current_columns_one_hot),\\n    (OrdinalEncoder(categories=current_ordinal_col_ordering_to_encode), current_columns_ordinal),\\n    n_jobs=1,\\n)\\n\\n# Apply transformation\\ncolumn_transform.fit(X_cat)\\nencoded_X_train = column_transform.transform(X_train)\\nencoded_X_test = column_transform.transform(X_test)\\nprint(\\\"Successfully encoded dataset.\\\")\\n\\nif scipy.sparse.issparse(encoded_X_train):\\n    encoded_X_train = encoded_X_train.toarray()\\nif scipy.sparse.issparse(encoded_X_test):\\n    encoded_X_test = encoded_X_test.toarray()\\n\\nprint(\\\"X_train\\\", np.shape(encoded_X_train))\\nprint(encoded_X_train[0:5])\\nprint(np.shape(encoded_X_test))\\nprint(encoded_X_test[0:5])\\n\\n# Transform y using label encoder\\nle = LabelEncoder().fit(y_cat)\\nencoded_y_train = le.transform(y_train)\\nencoded_y_test = le.transform(y_test)\\nprint(\\\"Successfully encoded dataset labels.\\\")\\n\\nprint(\\n    \\\"Train dataset contains \\\",\\n    encoded_X_train.shape,\\n    \\\", y dataset contains \\\",\\n    encoded_y_train.shape,\\n)\\nprint(\\n    \\\"Test dataset contains \\\",\\n    encoded_X_test.shape,\\n    \\\", y dataset contains \\\",\\n    encoded_y_test.shape,\\n)\";\n",
       "                var nbb_formatted_code = \"def calculate_current_order_of_ordinal_columns_to_encode():\\n    # Get common cols to feed them in proper order to ordinal encoder\\n    index_of_common_cols = order_of_ordinal_categories.columns.intersection(\\n        current_columns_ordinal\\n    )\\n    # Convert to list\\n    order_of_ordinal_categories_list = (\\n        order_of_ordinal_categories[index_of_common_cols].values.transpose().tolist()\\n    )\\n    return order_of_ordinal_categories_list\\n\\n\\n# Get current ordinal and one hot columns\\ntotal_column_list = X_cat.select_dtypes(include=\\\"object\\\").columns\\ncurrent_columns_one_hot = collect_current_one_hot_columns(total_column_list)\\ncurrent_columns_ordinal = collect_current_ordinal_columns(total_column_list)\\n\\ncurrent_ordinal_col_ordering_to_encode = (\\n    calculate_current_order_of_ordinal_columns_to_encode()\\n)\\n\\nprint(\\\"one hot: \\\", current_columns_one_hot)\\nprint(\\\"ordinal: \\\", current_columns_ordinal)\\n\\n# for debugging: unknown value in n-th column means n-th col from this is missing that value(s)\\n# print(index_of_common_cols)\\n# for col in X_train:\\n#    print(col, \\\": \\\", X_train[col].unique())\\n\\n# Create column transformer\\ncolumn_transform = make_column_transformer(\\n    (OneHotEncoder(), current_columns_one_hot),\\n    (\\n        OrdinalEncoder(categories=current_ordinal_col_ordering_to_encode),\\n        current_columns_ordinal,\\n    ),\\n    n_jobs=1,\\n)\\n\\n# Apply transformation\\ncolumn_transform.fit(X_cat)\\nencoded_X_train = column_transform.transform(X_train)\\nencoded_X_test = column_transform.transform(X_test)\\nprint(\\\"Successfully encoded dataset.\\\")\\n\\nif scipy.sparse.issparse(encoded_X_train):\\n    encoded_X_train = encoded_X_train.toarray()\\nif scipy.sparse.issparse(encoded_X_test):\\n    encoded_X_test = encoded_X_test.toarray()\\n\\nprint(\\\"X_train\\\", np.shape(encoded_X_train))\\nprint(encoded_X_train[0:5])\\nprint(np.shape(encoded_X_test))\\nprint(encoded_X_test[0:5])\\n\\n# Transform y using label encoder\\nle = LabelEncoder().fit(y_cat)\\nencoded_y_train = le.transform(y_train)\\nencoded_y_test = le.transform(y_test)\\nprint(\\\"Successfully encoded dataset labels.\\\")\\n\\nprint(\\n    \\\"Train dataset contains \\\",\\n    encoded_X_train.shape,\\n    \\\", y dataset contains \\\",\\n    encoded_y_train.shape,\\n)\\nprint(\\n    \\\"Test dataset contains \\\",\\n    encoded_X_test.shape,\\n    \\\", y dataset contains \\\",\\n    encoded_y_test.shape,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_current_order_of_ordinal_columns_to_encode():\n",
    "    # Get common cols to feed them in proper order to ordinal encoder\n",
    "    index_of_common_cols = order_of_ordinal_categories.columns.intersection(\n",
    "        current_columns_ordinal\n",
    "    )\n",
    "    # Convert to list\n",
    "    order_of_ordinal_categories_list = (\n",
    "        order_of_ordinal_categories[index_of_common_cols].values.transpose().tolist()\n",
    "    )\n",
    "    return order_of_ordinal_categories_list\n",
    "\n",
    "\n",
    "# Get current ordinal and one hot columns\n",
    "total_column_list = X_cat.select_dtypes(include=\"object\").columns\n",
    "current_columns_one_hot = collect_current_one_hot_columns(total_column_list)\n",
    "current_columns_ordinal = collect_current_ordinal_columns(total_column_list)\n",
    "\n",
    "current_ordinal_col_ordering_to_encode = (\n",
    "    calculate_current_order_of_ordinal_columns_to_encode()\n",
    ")\n",
    "\n",
    "print(\"one hot: \", current_columns_one_hot)\n",
    "print(\"ordinal: \", current_columns_ordinal)\n",
    "\n",
    "# for debugging: unknown value in n-th column means n-th col from this is missing that value(s)\n",
    "# print(index_of_common_cols)\n",
    "# for col in X_train:\n",
    "#    print(col, \": \", X_train[col].unique())\n",
    "\n",
    "# Create column transformer\n",
    "column_transform = make_column_transformer(\n",
    "    (OneHotEncoder(), current_columns_one_hot),\n",
    "    (\n",
    "        OrdinalEncoder(categories=current_ordinal_col_ordering_to_encode),\n",
    "        current_columns_ordinal,\n",
    "    ),\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "# Apply transformation\n",
    "column_transform.fit(X_cat)\n",
    "encoded_X_train = column_transform.transform(X_train)\n",
    "encoded_X_test = column_transform.transform(X_test)\n",
    "print(\"Successfully encoded dataset.\")\n",
    "\n",
    "if scipy.sparse.issparse(encoded_X_train):\n",
    "    encoded_X_train = encoded_X_train.toarray()\n",
    "if scipy.sparse.issparse(encoded_X_test):\n",
    "    encoded_X_test = encoded_X_test.toarray()\n",
    "\n",
    "print(\"X_train\", np.shape(encoded_X_train))\n",
    "print(encoded_X_train[0:5])\n",
    "print(np.shape(encoded_X_test))\n",
    "print(encoded_X_test[0:5])\n",
    "\n",
    "# Transform y using label encoder\n",
    "le = LabelEncoder().fit(y_cat)\n",
    "encoded_y_train = le.transform(y_train)\n",
    "encoded_y_test = le.transform(y_test)\n",
    "print(\"Successfully encoded dataset labels.\")\n",
    "\n",
    "print(\n",
    "    \"Train dataset contains \",\n",
    "    encoded_X_train.shape,\n",
    "    \", y dataset contains \",\n",
    "    encoded_y_train.shape,\n",
    ")\n",
    "print(\n",
    "    \"Test dataset contains \",\n",
    "    encoded_X_test.shape,\n",
    "    \", y dataset contains \",\n",
    "    encoded_y_test.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6583060e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         1.        ]\n",
      " [0.99999985 0.00000015]\n",
      " [0.         1.        ]\n",
      " [0.99999997 0.00000003]\n",
      " [0.00001758 0.99998242]\n",
      " [1.         0.        ]\n",
      " [0.85114924 0.14885076]\n",
      " [1.         0.        ]\n",
      " [0.00594469 0.99405531]\n",
      " [0.         1.        ]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"# Create a Bayes Classifier\\nnbayes = CategoricalNB()\\n\\n# Train the model using the training sets\\nnbayes.fit(encoded_X_train, y_train)\\n\\n# Predict the response for test dataset\\ny_pred = nbayes.predict(encoded_X_test)\\ny_pred_probas = nbayes.predict_proba(encoded_X_test)\\nprint(y_pred_probas[0:10])\";\n",
       "                var nbb_formatted_code = \"# Create a Bayes Classifier\\nnbayes = CategoricalNB()\\n\\n# Train the model using the training sets\\nnbayes.fit(encoded_X_train, y_train)\\n\\n# Predict the response for test dataset\\ny_pred = nbayes.predict(encoded_X_test)\\ny_pred_probas = nbayes.predict_proba(encoded_X_test)\\nprint(y_pred_probas[0:10])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a Bayes Classifier\n",
    "nbayes = CategoricalNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "nbayes.fit(encoded_X_train, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = nbayes.predict(encoded_X_test)\n",
    "y_pred_probas = nbayes.predict_proba(encoded_X_test)\n",
    "print(y_pred_probas[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d835b50d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.15384615384616 %\n",
      "F1 score: 94.13533681411134 %\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"# Model Accuracy, how often is the classifier correct?\\nprint(\\\"Accuracy:\\\", metrics.accuracy_score(y_test, y_pred) * 100, \\\"%\\\")\\nprint(\\\"F1 score:\\\", metrics.f1_score(y_test, y_pred, average=\\\"weighted\\\") * 100, \\\"%\\\")\";\n",
       "                var nbb_formatted_code = \"# Model Accuracy, how often is the classifier correct?\\nprint(\\\"Accuracy:\\\", metrics.accuracy_score(y_test, y_pred) * 100, \\\"%\\\")\\nprint(\\\"F1 score:\\\", metrics.f1_score(y_test, y_pred, average=\\\"weighted\\\") * 100, \\\"%\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred) * 100, \"%\")\n",
    "print(\"F1 score:\", metrics.f1_score(y_test, y_pred, average=\"weighted\") * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cac59494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137593\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"# Get cost of classification\\nclassification_cost = dataset_costs[X_cat.columns].sum(axis=1)[0]\\nprint(classification_cost)\";\n",
       "                var nbb_formatted_code = \"# Get cost of classification\\nclassification_cost = dataset_costs[X_cat.columns].sum(axis=1)[0]\\nprint(classification_cost)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get cost of classification\n",
    "classification_cost = dataset_costs[X_cat.columns].sum(axis=1)[0]\n",
    "print(classification_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b985758",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "useful links:\n",
    "\n",
    "https://dev.to/codinghappinessweb/analysing-dataset-using-naive-bayes-classifier-3d7o\n",
    "https://towardsdatascience.com/15-tips-and-tricks-for-jupyter-notebook-that-will-ease-your-coding-experience-e469207ac95c\n",
    "https://towardsdatascience.com/guide-to-encoding-categorical-features-using-scikit-learn-for-machine-learning-5048997a5c79\n",
    "https://towardsdatascience.com/naive-bayes-classifier-how-to-successfully-use-it-in-python-ecf76a995069\n",
    "https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
